I"²$<p><br /></p>

<p>OUTLINES</p>

<ul>
  <li>MULTIVARIATE LINEAR REGRESSION</li>
  <li>BATCH/ STOCHASTIC GRADIENT DESCENT</li>
  <li>NORMAL EQUATION 
<br /></li>
</ul>

<hr />

<h2 id="1-multivariate-linear-regression">1. Multivariate Linear Regression</h2>
<p><br /></p>

<h2 id="11-multiple-features"><strong>1.1. Multiple Features</strong></h2>
<p><br /></p>

<ul>
  <li>
    <p>$x^{i}$ : $i_{th}$ input variables (set of features) <br /></p>
  </li>
  <li>
    <p>$y^{i}$ : $i_{th}$ output variable (target variable) that weâ€™re trying to predict <br /></p>
  </li>
  <li>
    <p>$ (x^{i}, y^{i})$ For $i = 1, 2, 3,â€¦,m$ : training dataset <br />
<br /></p>
  </li>
  <li>
    <p><strong>Hypothesis</strong></p>

    <p>â€ƒâ€ƒâ€ƒâ€ƒâ€ƒ $ h_{\theta}(x) = \sum \limits_{j=1}^{n} \theta_{j}x_{j} $ <br /></p>

    <ul>
      <li>$x_{j}$ For $j = 1, 2, 3,â€¦,n$ : value of $j_{th}$ feature of all n input features</li>
      <li>set $x_{0}$ as 0 (intercept term, b) <br /></li>
      <li>$\theta_{j}$ For $j = 1, 2, 3,â€¦,n$ : $j_{th}$ parameter of n parameters each  (weights) parameterizing the space of linear functions mapping from x to y <br /> <br /></li>
    </ul>
  </li>
  <li>
    <p><strong>Matrix Representation of Hypothesis</strong> <br /></p>

    <p>â€ƒâ€ƒâ€ƒâ€ƒ $\theta = \begin{bmatrix} \theta_{1} \ \theta_{2} \ . \ . \ . \ \theta_{n} \end{bmatrix}$</p>

    <p>â€ƒâ€ƒâ€ƒâ€ƒ $ x^{i} = \begin{bmatrix} x^{i}<em>{1} \ x^{i}</em>{2} \ . \ . \ . \ x^{i}_{n} $</p>

    <p>â€ƒâ€ƒâ€ƒâ€ƒ $h(x^{i}) = \theta^{T}x^{i}$</p>
  </li>
</ul>

<p><br /></p>

<h2 id="12-cost-function"><strong>1.2. Cost Function</strong></h2>
<p><br /></p>

<ul>
  <li>Trying to minimize the deviations of $h(x)$ from $y$ <br /></li>
  <li>Least Mean Square (LMS algorithm) <br /></li>
</ul>

<p>â€ƒâ€ƒâ€ƒâ€ƒ $ J(\theta) = \sum\limits_{i=1}^{m} (h_{\theta}(x^{i}) - y^{i})^{2} $</p>

<ul>
  <li><strong>LMS algorithm with Gradient Descent</strong>
    <ul>
      <li>algorithm starts with some initial guess with $\theta_{j}$ with radomized values and repeatedly updates the paratmeters using gradient descent algorithm <br /></li>
      <li>take partial derivative with respect to every parameter multiplied by learning rate ($\alpha$) and substract it from previous value of paramter <br /></li>
    </ul>

    <p>â€ƒâ€ƒâ€ƒâ€ƒ $ \theta_{j} := \theta_{j} - \alpha\frac{\partial J(\theta)}{\partial \theta_{j}}$ â€ƒ $For j = 1,2,3,â€¦,n $ 
  <br /></p>
    <ul>
      <li>$\alpha$ (learning rate) : regulates the speed of adjusting parameters so that prevents over-fitting
        <ul>
          <li>try multiple cases and find best one</li>
        </ul>
      </li>
      <li>
        <p>repeat updating parameters for every step of gradient descent <br /></p>
      </li>
      <li>
        <p><strong>Partial Derivative of $J(\theta)$</strong>
  <img src="https://user-images.githubusercontent.com/92680829/226507002-653a8d8b-8c7c-443e-a81d-18e4b0076a7e.png" width="400" /></p>
      </li>
      <li>$\theta_{j} := \theta_{j} - \alpha (h_{\theta}(x) - y)x_{j} $ â€ƒ $ For j = 1,2,3,â€¦,n $</li>
      <li>larger change will be made with larger error term ($ h(\theta) - y $)</li>
      <li>Repeat the update untill <strong>convergence</strong></li>
    </ul>
  </li>
</ul>

<hr />

<h2 id="2-batch-gradient-descent-bgd-vs-stochastic-gradient-descent-sgd"><strong>2. Batch Gradient Descent (BGD) vs Stochastic Gradient Descent (SGD)</strong></h2>
<p><br /></p>

<ul>
  <li>In <strong>BGD</strong> (1 update per batch):
    <ul>
      <li>the algorithm updates the model parameters after processing the entire training dataset.</li>
      <li>The cost function $ J(\theta) $ is first computed over all the training examples and then the gradient of the cost function with respect to the parameters is computed. <br />
  â€ƒâ€ƒâ€ƒâ€ƒ $ \theta_{j} := \theta_{j} - \alpha (h_{\theta}(x) - y)x_{j} $ for every j
  <img src="https://user-images.githubusercontent.com/92680829/226516910-a83cf250-f717-47b4-8197-79227691fc6c.png" width="330" /></li>
    </ul>
  </li>
</ul>

<p><br /></p>

<ul>
  <li>In <strong>SGD</strong> (1 update per data point):
    <ul>
      <li>updates the model parameters after processing each individual training example.</li>
      <li>for each iteration, the algorithm randomly selects one training example, computes the gradient with respect to that example, and then updates the parameters based on that gradient.
  <img src="https://user-images.githubusercontent.com/92680829/226513938-b576bc1f-6352-457b-a37a-cd207faee8c0.png" width="450" />
  <img src="https://user-images.githubusercontent.com/92680829/158748465-5e302586-7b60-4960-b7a4-bd43a121bbce.png" width="330" /></li>
    </ul>
  </li>
</ul>

<p><br /></p>

<ul>
  <li>BGD processes the entire training set at each iteration, which is computationally expensive but accurate.</li>
  <li>SGD processes a signle training example at a time so that can coverge much faster.</li>
  <li>While SGD has economical advantage over BGD, it may never be converge on global minimum, only oscillating around the local minimum.</li>
  <li>Therefore, BGD can converge to the optimum more accurately and quickly on small datasets, while SGD can converge faster on large datasets.
<br /></li>
</ul>

<h3 id="check-for-convergence-with-stochastic-gradient-descent"><strong>Check for Convergence with Stochastic gradient descent</strong></h3>

<ul>
  <li>how to check SGD has convergd to global minimum (at least close)</li>
  <li>
    <p>how to tune learning rate Î± to get proper convergence?</p>
  </li>
  <li><strong>Plotting $ J(\theta) $ averaged over N examples</strong>
    <ol>
      <li>decrease learning rate (upper left)
        <ul>
          <li>slower the convergence</li>
          <li>but obtain slightly better cost (negligible sometimes)</li>
        </ul>
      </li>
      <li>increase N (&gt;= 5000) (upper right)
        <ul>
          <li>also takes more time to plot (longer time to get single plotting point)</li>
          <li>can smoothen the cost line</li>
        </ul>
      </li>
      <li>increase N (lower left)
        <ul>
          <li>line will fluctuate too much, preventing you from seeing actual trend</li>
          <li>if you elevate N, then you can see whatâ€™s actually going on</li>
        </ul>
      </li>
      <li>decrease learning rate (lower right)
        <ul>
          <li>it shows that your algorithm fails to converge to minimum, (diverging, fails to find optimal parameters)</li>
          <li>you should adjust your learning rate smaller, so that it can converge</li>
        </ul>
      </li>
    </ol>

    <p><br /></p>

    <p><img src="https://user-images.githubusercontent.com/92680829/158756682-e98ca189-c71e-48a8-929a-9718bbb3967b.png" width="500" /></p>
  </li>
</ul>

<p><br /></p>

<ul>
  <li><strong>Learning rate (Î±)</strong>
    <ul>
      <li>typically, Î± helds constant through entire learning process</li>
      <li>but, can also slowly decrease Î± over time (if you want the model to converge better)
        <ul>
          <li><strong>Î± = $\beta\,$ / ($\,$iterationNumber$\,$ + $\gamma$)</strong></li>
          <li>need to take additional time to decide what $\beta$ and $\gamma$ are</li>
          <li>guaranteed to converge somewhere rathter than oscillating around it</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>SGD can be a good algorithm for massive training examples</li>
</ul>

<hr />

<h2 id="3-normal-equation">3. Normal Equation</h2>

<ul>
  <li>Closed-form solution for linear regression problems, which can be used to find the optimal parameters of a linear model. (only applicable to linear regresson case)</li>
  <li>provides a way to compute the optimized parameter vector theta directly from the training data by solving the equation, without the need for an iterative optimization algorithm such as gradient descent.</li>
  <li>Explicitly takes derivatives of cost function with respect to $\theta_{j}$s and solve by setting it to be 0.</li>
</ul>

<h3 id="matrix-dervatives">Matrix Dervatives</h3>

<p><img width="500" alt="Screen Shot 2023-03-22 at 10 20 37 PM" src="https://user-images.githubusercontent.com/92680829/226919657-9eb90839-890c-4153-a231-8b98cc2b3daf.png" /></p>

<h3 id="properties-of-nabla-and-trace-of-matrix">Properties of $\nabla$ and Trace of Matrix</h3>

<p><img width="594" alt="Screen Shot 2023-03-22 at 10 20 42 PM" src="https://user-images.githubusercontent.com/92680829/226920487-f70958cd-339e-44b5-b51f-79a4eb51d8cf.png" /></p>

<h3 id="least-mean-square-solved-with-normal-equation">Least Mean Square solved with Normal Equation</h3>

<p><img width="720" alt="Screen Shot 2023-03-22 at 10 20 47 PM" src="https://user-images.githubusercontent.com/92680829/226920887-661939ea-7392-4103-86df-d515270b3126.png" /></p>

<ul>
  <li>The amout of computations needed to solve normal equation depends on n (the number of parameters) with $O(n^{2})$</li>
  <li>For dataset with smaller number of paramters, solving normal equation instead of iterative gradient descent will be efficient.</li>
</ul>

<hr />

<h3 id="for-this-session-weve-learnt">For this session, weâ€™ve learnt</h3>
<ol>
  <li>How to optimize parameters for multivariate lienar regression</li>
  <li>Differnece between BGD and SGD</li>
  <li>Normal Equation as an alternative to Gradient Descent (Iterative optimization process)</li>
</ol>
:ET