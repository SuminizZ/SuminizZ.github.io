I"5)<p><br /></p>

<h1 id="planar-data-classification-with-one-hidden-layer"><strong>Planar data classification with one hidden layer</strong></h1>
<ul>
  <li>for this session, letâ€™s develoop a planar data classifier with shallow neural network with only 1 hidden layer</li>
  <li>all references come from <a href="https://github.com/Kulbear/deep-learning-coursera/blob/master/Neural%20Networks%20and%20Deep%20Learning/Planar%20data%20classification%20with%20one%20hidden%20layer.ipynb">here!</a></li>
  <li>This chapter covers all below,
    <ul>
      <li>Implement a binary classification neural network with a single hidden layer</li>
      <li>For binary classification, use activation function as non-linaer function such as tanh or sigmoid</li>
      <li>Compute the cross entropy loss</li>
      <li>Implement forward and backward propagation to optimizes the weights</li>
      <li>Test Model Performance with Different Hidden Unit Size and Datasets</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="1-prepare-required-packages--load-dataset"><strong>1. Prepare required packages &amp; Load Dataset</strong></h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">unittest</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">testcase</span> <span class="o">--</span><span class="n">trusted</span><span class="o">-</span><span class="n">host</span> <span class="n">pypi</span><span class="p">.</span><span class="n">org</span> <span class="o">--</span><span class="n">trusted</span><span class="o">-</span><span class="n">host</span> <span class="n">files</span><span class="p">.</span><span class="n">pythonhosted</span><span class="p">.</span><span class="n">org</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">scikit</span><span class="o">-</span><span class="n">learn</span>
</code></pre></div></div>

<ul>
  <li>How to use <strong>plt.contourf()</strong> to draw contour plot
    <ul>
      <li><a href="https://m31phy.tistory.com/220">Reference from here</a></li>
      <li><a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.contour.html">Official Documents here</a></li>
    </ul>
  </li>
  <li><a href="https://rfriend.tistory.com/352"><strong>np.c_</strong></a>
    <ul>
      <li><img src="https://user-images.githubusercontent.com/92680829/168471744-79a92162-1890-4a7c-9da7-bafe0ee4e2db.png" width="400" /></li>
    </ul>
  </li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># planar_utils.py
</span>
<span class="k">def</span> <span class="nf">plot_decision_boundary</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">title</span><span class="p">):</span>
    <span class="c1"># Set min and max values and give it some padding
</span>    <span class="n">x1_min</span><span class="p">,</span> <span class="n">x1_max</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:].</span><span class="nb">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:].</span><span class="nb">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">x2_min</span><span class="p">,</span> <span class="n">x2_max</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:].</span><span class="nb">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:].</span><span class="nb">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">h</span> <span class="o">=</span> <span class="mf">0.01</span>
    
    <span class="c1"># Generate a grid of points with distance h between them
</span>    <span class="n">x1x1</span><span class="p">,</span> <span class="n">x2x2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">x1_min</span><span class="p">,</span> <span class="n">x1_max</span><span class="p">,</span> <span class="n">h</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">x2_min</span><span class="p">,</span> <span class="n">x2_max</span><span class="p">,</span> <span class="n">h</span><span class="p">))</span>
    
    <span class="c1"># Predict the function value for the whole grid
</span>    <span class="n">Z</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">c_</span><span class="p">[</span><span class="n">x1x1</span><span class="p">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">x2x2</span><span class="p">.</span><span class="n">ravel</span><span class="p">()])</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">Z</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x1x1</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
    
    <span class="c1"># Plot the contour and training examples
</span>    <span class="n">plt</span><span class="p">.</span><span class="n">contourf</span><span class="p">(</span><span class="n">x1x1</span><span class="p">,</span> <span class="n">x2x2</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="p">.</span><span class="n">cm</span><span class="p">.</span><span class="n">Spectral</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'x2'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'x1'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:],</span> <span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:],</span> <span class="n">c</span><span class="o">=</span><span class="n">Y</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="p">.</span><span class="n">cm</span><span class="p">.</span><span class="n">Spectral</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s">'black'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    
<span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="s">"""
    Compute the sigmoid of x
    Arguments:
    x -- A scalar or numpy array of any size.
    Return:
    s -- sigmoid(x)
    """</span>
    
    <span class="n">s</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">s</span>


<span class="k">def</span> <span class="nf">load_planar_dataset</span><span class="p">():</span>
    <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">m</span> <span class="o">=</span> <span class="mi">400</span>         <span class="c1"># number of examples
</span>    <span class="n">N</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">m</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>       <span class="c1"># number of points per class
</span>    <span class="n">D</span> <span class="o">=</span> <span class="mi">2</span>       <span class="c1"># dimensionality (2 nodes in single hidden layer)
</span>    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">m</span><span class="p">,</span><span class="n">D</span><span class="p">))</span>       <span class="c1"># data ma trix where each row is a single example 
</span>    <span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">m</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s">'uint8'</span><span class="p">)</span>       <span class="c1"># labels vector (0 for red, 1 for blue)
</span>    <span class="n">a</span> <span class="o">=</span> <span class="mi">4</span>       <span class="c1"># maximum ray of the flower
</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
        <span class="n">ix</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="o">*</span><span class="n">j</span><span class="p">,</span><span class="n">N</span><span class="o">*</span><span class="p">(</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">j</span><span class="o">*</span><span class="mf">3.12</span><span class="p">,(</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="mf">3.12</span><span class="p">,</span><span class="n">N</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">)</span><span class="o">*</span><span class="mf">0.2</span>       <span class="c1"># theta
</span>        <span class="n">r</span> <span class="o">=</span> <span class="n">a</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">4</span><span class="o">*</span><span class="n">t</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">)</span><span class="o">*</span><span class="mf">0.2</span>       <span class="c1"># radius
</span>        <span class="n">X</span><span class="p">[</span><span class="n">ix</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">c_</span><span class="p">[</span><span class="n">r</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">sin</span><span class="p">(</span><span class="n">t</span><span class="p">),</span> <span class="n">r</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">cos</span><span class="p">(</span><span class="n">t</span><span class="p">)]</span>
        <span class="n">Y</span><span class="p">[</span><span class="n">ix</span><span class="p">]</span> <span class="o">=</span> <span class="n">j</span>

    <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">T</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">Y</span><span class="p">.</span><span class="n">T</span>

    <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span>


<span class="k">def</span> <span class="nf">load_extra_datasets</span><span class="p">():</span>  
    <span class="n">N</span> <span class="o">=</span> <span class="mi">200</span>
    <span class="n">noisy_circles</span> <span class="o">=</span> <span class="n">sklearn</span><span class="p">.</span><span class="n">datasets</span><span class="p">.</span><span class="n">make_circles</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="n">N</span><span class="p">,</span> <span class="n">factor</span><span class="o">=</span><span class="p">.</span><span class="mi">5</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="p">.</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">noisy_moons</span> <span class="o">=</span> <span class="n">sklearn</span><span class="p">.</span><span class="n">datasets</span><span class="p">.</span><span class="n">make_moons</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="n">N</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="p">.</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">blobs</span> <span class="o">=</span> <span class="n">sklearn</span><span class="p">.</span><span class="n">datasets</span><span class="p">.</span><span class="n">make_blobs</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="n">N</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">centers</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>
    <span class="n">gaussian_quantiles</span> <span class="o">=</span> <span class="n">sklearn</span><span class="p">.</span><span class="n">datasets</span><span class="p">.</span><span class="n">make_gaussian_quantiles</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">cov</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="n">N</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
    <span class="n">no_structure</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">noisy_circles</span><span class="p">,</span> <span class="n">noisy_moons</span><span class="p">,</span> <span class="n">blobs</span><span class="p">,</span> <span class="n">gaussian_quantiles</span><span class="p">,</span> <span class="n">no_structure</span>

</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span> 
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">testcase</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">sklearn</span><span class="p">,</span> <span class="n">sklearn</span><span class="p">.</span><span class="n">datasets</span><span class="p">,</span> <span class="n">sklearn</span><span class="p">.</span><span class="n">linear_model</span>

<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span> 

<span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  
</code></pre></div></div>

<ul>
  <li>testCases : provides some test examples to assess the correctness of your functions</li>
  <li>np.random.seed(x) : numpy random seed is a numerical value that generates a <strong>pseudo-random numbers</strong>. The value in the numpy <strong>random seed saves the state of randomness</strong>. If we call the seed function using value 1 multiple times, the <strong>computer displays the same random numbers</strong>.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">## Load Dataset
</span>
<span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">load_planar_dataset</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>   <span class="c1"># 2x400 matrix
</span><span class="k">print</span><span class="p">(</span><span class="n">Y</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>   <span class="c1"># 1x400 vector
</span><span class="k">print</span><span class="p">(</span><span class="n">Y</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>   <span class="c1"># training size
</span>
<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:],</span> <span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:],</span> <span class="n">c</span><span class="o">=</span><span class="n">Y</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s">'black'</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="p">.</span><span class="n">cm</span><span class="p">.</span><span class="n">Spectral</span><span class="p">)</span>     
<span class="n">plt</span><span class="p">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">label</span> <span class="o">=</span> <span class="s">'color'</span><span class="p">)</span>     <span class="c1"># red for 0, Blue for 1 
</span></code></pre></div></div>
<p><img width="191" alt="image" src="https://user-images.githubusercontent.com/92680829/168481094-fa303545-673d-48a6-bc84-d031dbf0bf5c.png" /></p>

<p><img width="498" alt="image" src="https://user-images.githubusercontent.com/92680829/168481116-d3051cd2-0916-47ec-abb2-251b32e372d0.png" /></p>

<p><br /></p>

<h2 id="2-simple-logistic-regression-classifier"><strong>2. Simple Logistic Regression Classifier</strong></h2>
<ul>
  <li>before jumping right into developing classifier with shallow neural network, letâ€™s firstly make relatively simple classifier with logistic regression model</li>
  <li>Through this, you can compare the performances of those two different algorithms</li>
  <li>Use convenient sklearn packages to import lr classifer</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">from</span> <span class="nn">sklearn.exceptions</span> <span class="kn">import</span> <span class="n">DataConversionWarning</span>
<span class="n">warnings</span><span class="p">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="n">action</span><span class="o">=</span><span class="s">'ignore'</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="n">DataConversionWarning</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">lr_clf</span> <span class="o">=</span> <span class="n">sklearn</span><span class="p">.</span><span class="n">linear_model</span><span class="p">.</span><span class="n">LogisticRegressionCV</span><span class="p">()</span>
<span class="n">lr_clf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">T</span><span class="p">,</span> <span class="n">Y</span><span class="p">.</span><span class="n">T</span><span class="p">)</span>    <span class="c1"># X.T : (D, m)
</span></code></pre></div></div>
<p><img width="240" alt="image" src="https://user-images.githubusercontent.com/92680829/168481147-88741a37-5701-4307-90c5-198bba4d9808.png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># plot decision boundary for separating classes (0, 1)
</span>
<span class="n">plot_decision_boundary</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span> <span class="p">:</span> <span class="n">lr_clf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="s">"Logistic Regression"</span><span class="p">)</span>   
</code></pre></div></div>

<p><img width="445" alt="image" src="https://user-images.githubusercontent.com/92680829/168481220-bdba2cd5-7655-4219-9b3e-eec03e270daa.png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Prediction Accuracy 
</span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="n">LR_result</span> <span class="o">=</span> <span class="n">lr_clf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">T</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Accuracy with Logistic Regression Classifier : {0}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">Y</span><span class="p">[</span><span class="mi">0</span><span class="p">,:],</span> <span class="n">LR_result</span><span class="p">)))</span>


<span class="c1"># instead of using sklearn library, you can also calcuate accuracy with code below
# dot result gives 1 only when Y and predicted value equals each other (either 0 or 1)
</span>
<span class="k">print</span><span class="p">(</span><span class="nb">float</span><span class="p">((</span><span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">LR_result</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">Y</span><span class="p">,</span><span class="mi">1</span> <span class="o">-</span> <span class="n">LR_result</span><span class="p">))</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">Y</span><span class="p">.</span><span class="n">size</span><span class="p">)))</span>   
</code></pre></div></div>
<p><img width="519" alt="image" src="https://user-images.githubusercontent.com/92680829/168481244-07c9f91c-f327-4eff-8a55-0c61c62979b3.png" /></p>

<ul>
  <li>The performance of logistic regression algorithm represented as accuracy score was not great, which is 47%.</li>
  <li>This result implies that planar dataset is not linearly separable</li>
  <li>So you definitely need another algorithm, hope neural network with a single layer would work better</li>
</ul>

<p><br /></p>

<h2 id="3-define-neural-network-model-structure"><strong>3. Define Neural Network Model Structure</strong></h2>
<ul>
  <li>Now, letâ€™s finally make Neural Network model with one hidden layer to predict classes for planar dataset</li>
  <li>Here is the representation of our model
    <ul>
      <li><img src="https://user-images.githubusercontent.com/92680829/166148291-02e9da43-8f31-4841-bc11-e5a81683bbca.png" width="550" /></li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h3 id="gradient-descent-loop"><strong>Gradient Descent Loop</strong></h3>
<ul>
  <li>Implement forward propagation â€“&gt; predict</li>
  <li>Compute loss</li>
  <li>Implement backward propagation to get the gradients</li>
  <li>Update parameters (gradient descent)</li>
</ul>

<p><br /></p>

<h3 id="1-forward-propagation"><strong>1) Forward Propagation</strong></h3>
<ul>
  <li>400 examples with two features, x1 and x2</li>
  <li>Single hidden layer contains 4 training nodes with identical activation function <strong>tanh</strong></li>
  <li>
    <p>The activation function of output layer is sigmoid as it should return either 0 or 1 (threshold 0.5)</p>
  </li>
  <li><img src="https://user-images.githubusercontent.com/92680829/166148546-3dc96ddf-b90d-445d-94ac-7becc3f1c59b.png" width="300" /></li>
</ul>

<p><br /></p>

<h3 id="2-computing-cost"><strong>2) Computing Cost</strong></h3>

<ul>
  <li>Cost function of NN equals to that of logstic regression</li>
  <li>to make convex function</li>
</ul>

<p><img src="https://user-images.githubusercontent.com/92680829/166148666-3cd0a56f-764a-400c-ab74-788c673beb46.png" width="450" /></p>

<p><br /></p>

<h3 id="3-back-propagation-for-gradient-descent"><strong>3) Back-Propagation for Gradient Descent</strong></h3>
<ul>
  <li>J = J - Î± * dJ/dw (Î±, learning rate)</li>
  <li>For Gradient Descent, you need to calculate the partial derivative of Cost(L) by the parameter of interest</li>
  <li>Then, if you want to compute <strong>partial derivative of L</strong> by <strong>w (dw)</strong>, then you firstly have to compute it by <strong>a (da)</strong>, then by <strong>z (dz)</strong>, and then finally by <strong>w</strong>,</li>
  <li>Same applies to parameter <strong>b</strong>
    <ul>
      <li><strong>dL/dw (dW) = dL/da (da) * da/dz (dz) * dz/dw</strong></li>
      <li>How to back proagate with sigmoid activation function</li>
      <li><img src="https://user-images.githubusercontent.com/92680829/164571295-d51918ba-9d2f-4c60-add4-c6282b47bd85.png" width="300" /></li>
    </ul>
  </li>
</ul>

<p><br /></p>

<ul>
  <li><strong>Derivative of Multiple Activation Functions : da/dz (dz)</strong>
    <ul>
      <li>here are the graphs and derivatives of various types of activation function</li>
      <li><img src="https://user-images.githubusercontent.com/92680829/167841964-d9483851-6903-45a3-8d4f-c96b399ceb0e.png" width="600" /></li>
    </ul>
  </li>
</ul>

<h3 id="summary-of-gradient-descent-for-our-model"><strong>Summary of Gradient Descent for Our Model</strong></h3>
<ul>
  <li>we have one <strong>input layer</strong> (400 examples with 2 features) : x (2, 400)</li>
  <li><strong>hidden layer</strong> (4 nodes with â€˜tanhâ€™ activation function) : W[1] (4, 2), Z[1], b[1] â€“&gt; a[1]</li>
  <li>one <strong>output layer</strong> (one node with sigmoid activation function) : W[2], Z[2], b[2] â€“&gt; a[2]
    <ul>
      <li>
        <p><img src="https://user-images.githubusercontent.com/92680829/167842937-abd9c9b8-eb05-41d2-a16f-fe1935c20605.png" width="500" /></p>
      </li>
      <li>g[1]â€™(z[1]) here is 1-a[1]^2 (as g(z) is tanh(z))</li>
      <li>1 - np.pow(A1, 2)</li>
    </ul>
  </li>
</ul>

<h2 id="4-build-model"><strong>4. Build Model</strong></h2>
<ul>
  <li>Weâ€™ve just defined the model structure, decision boudary, cost function and the loop process for gradient descent!</li>
  <li>Letâ€™s build functions named â€˜nn_model()â€™ to realize desired neural network</li>
</ul>

<h4 id="set-sizes-of-each-layer-input-hidden-and-output">Set sizes of each layer, input, hidden and output</h4>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="k">def</span> <span class="nf">layer_sizes</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span><span class="n">s</span><span class="p">:</span>
    <span class="n">nx</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>    <span class="c1"># (2, 400) -&gt; 2 : size of input layer
</span>    <span class="n">nh</span> <span class="o">=</span> <span class="mi">4</span>             <span class="c1"># nodes 9
</span>    <span class="n">ny</span> <span class="o">=</span> <span class="n">Y</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>    <span class="c1"># (1, 400) -&gt; 1 : size of output layer
</span>    
    <span class="k">return</span> <span class="p">(</span><span class="n">nx</span><span class="p">,</span> <span class="n">nh</span><span class="p">,</span> <span class="n">ny</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="initialize-model-parameters-randomly">Initialize model parameters randomly</h4>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">initialize_params</span><span class="p">(</span><span class="n">nx</span><span class="p">,</span> <span class="n">nh</span><span class="p">,</span> <span class="n">ny</span><span class="p">):</span>
    <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>     <span class="c1"># set random state so that our outcomes have same value even with randomized initialization
</span>    
    <span class="n">W1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="n">nh</span><span class="p">,</span> <span class="n">nx</span><span class="p">)</span><span class="o">*</span><span class="mf">0.01</span> <span class="c1"># from input to hidden layer (4, 2)
</span>    <span class="n">b1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">nh</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>     <span class="c1"># (4, 1)
</span>    <span class="n">W2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="n">ny</span><span class="p">,</span> <span class="n">nh</span><span class="p">)</span><span class="o">*</span><span class="mf">0.01</span>   <span class="c1"># (1, 4)
</span>    <span class="n">b2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">ny</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>     <span class="c1"># (1, 1)
</span>    
    <span class="c1"># confirm that each param has the right shape
</span>    <span class="k">assert</span><span class="p">(</span><span class="n">W1</span><span class="p">.</span><span class="n">shape</span><span class="o">==</span><span class="p">(</span><span class="n">nh</span><span class="p">,</span> <span class="n">nx</span><span class="p">)</span> <span class="ow">and</span> <span class="n">b1</span><span class="p">.</span><span class="n">shape</span><span class="o">==</span><span class="p">(</span><span class="n">nh</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="ow">and</span> <span class="n">W2</span><span class="p">.</span><span class="n">shape</span><span class="o">==</span><span class="p">(</span><span class="n">ny</span><span class="p">,</span> <span class="n">nh</span><span class="p">)</span> <span class="ow">and</span> <span class="n">b2</span><span class="p">.</span><span class="n">shape</span><span class="o">==</span><span class="p">(</span><span class="n">ny</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    
    <span class="n">params</span> <span class="o">=</span> <span class="p">{</span><span class="s">'W1'</span> <span class="p">:</span> <span class="n">W1</span><span class="p">,</span> <span class="s">'b1'</span> <span class="p">:</span> <span class="n">b1</span><span class="p">,</span> <span class="s">'W2'</span> <span class="p">:</span> <span class="n">W2</span><span class="p">,</span> <span class="s">'b2'</span> <span class="p">:</span> <span class="n">b2</span><span class="p">}</span>
    
    <span class="k">return</span> <span class="n">params</span>
</code></pre></div></div>

<h4 id="forward-propagation">Forward Propagation</h4>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">fp</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="n">W1</span><span class="p">,</span> <span class="n">b1</span><span class="p">,</span> <span class="n">W2</span><span class="p">,</span> <span class="n">b2</span> <span class="o">=</span> <span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s">'W1'</span><span class="p">],</span> <span class="n">params</span><span class="p">[</span><span class="s">'b1'</span><span class="p">],</span> <span class="n">params</span><span class="p">[</span><span class="s">'W2'</span><span class="p">],</span> <span class="n">params</span><span class="p">[</span><span class="s">'b2'</span><span class="p">])</span> 
    
    <span class="n">Z1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W1</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span> <span class="o">+</span> <span class="n">b1</span>  <span class="c1"># (4, 2) x (2, 400) = (4, 400) + b(4, 1) broadcasting
</span>    <span class="n">A1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">Z1</span><span class="p">)</span>
    <span class="n">Z2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W2</span><span class="p">,</span> <span class="n">A1</span><span class="p">)</span> <span class="o">+</span> <span class="n">b2</span>  <span class="c1"># (1, 4) x (4, 400) = (1, 400) + b(1, 1) broadcasting
</span>    <span class="n">A2</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">Z2</span><span class="p">)</span>          <span class="c1"># probability that x is 1
</span>    
    <span class="k">assert</span><span class="p">(</span><span class="n">A2</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    
    <span class="n">cache</span> <span class="o">=</span> <span class="p">{</span><span class="s">'Z1'</span> <span class="p">:</span> <span class="n">Z1</span><span class="p">,</span> <span class="s">'A1'</span> <span class="p">:</span> <span class="n">A1</span><span class="p">,</span> <span class="s">'Z2'</span> <span class="p">:</span> <span class="n">Z2</span><span class="p">,</span> <span class="s">'A2'</span> <span class="p">:</span> <span class="n">A2</span><span class="p">}</span>
           
    <span class="k">return</span> <span class="n">cache</span>
</code></pre></div></div>

<h4 id="calculate-cost">Calculate Cost</h4>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># now calculate the cost (amount of deviation of A2 from Y)
# cost function (J(a))
</span>    <span class="c1"># J= âˆ’1/m (i=1~i=400âˆ‘( y(i)log(a[2](i)) + (1âˆ’y(i))log(1âˆ’a[2](i)) )
</span>
<span class="k">def</span> <span class="nf">compute_cost</span><span class="p">(</span><span class="n">A2</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">Y</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    
    <span class="n">tmp</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">A2</span><span class="p">),</span> <span class="n">Y</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">A2</span><span class="p">),</span> <span class="mi">1</span><span class="o">-</span><span class="n">Y</span><span class="p">)</span>
    <span class="n">cost</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">tmp</span><span class="p">)</span><span class="o">/</span><span class="n">m</span>
    <span class="n">cost</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">cost</span><span class="p">))</span>    <span class="c1"># remove axis whose size is 1 
</span>    
    <span class="k">assert</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">cost</span><span class="p">,</span> <span class="nb">float</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">cost</span>
</code></pre></div></div>

<h4 id="compute-gradient-descent">Compute gradient descent</h4>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># now let's compute gradient descent of neural network with back-propagation
</span>
<span class="k">def</span> <span class="nf">bp</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">cache</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>
    <span class="s">""""
    Returns: grads -- gradients with respect to different parameters (dW1, dW2, db1, db2)
    """</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>   <span class="c1"># 400
</span>    
    <span class="n">W1</span><span class="p">,</span> <span class="n">b1</span><span class="p">,</span> <span class="n">W2</span><span class="p">,</span> <span class="n">b2</span> <span class="o">=</span> <span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s">'W1'</span><span class="p">],</span> <span class="n">params</span><span class="p">[</span><span class="s">'b1'</span><span class="p">],</span> <span class="n">params</span><span class="p">[</span><span class="s">'W2'</span><span class="p">],</span> <span class="n">params</span><span class="p">[</span><span class="s">'b2'</span><span class="p">])</span>     
    <span class="n">Z1</span><span class="p">,</span> <span class="n">A1</span><span class="p">,</span> <span class="n">Z2</span><span class="p">,</span> <span class="n">A2</span> <span class="o">=</span> <span class="p">(</span><span class="n">cache</span><span class="p">[</span><span class="s">'Z1'</span><span class="p">],</span> <span class="n">cache</span><span class="p">[</span><span class="s">'A1'</span><span class="p">],</span> <span class="n">cache</span><span class="p">[</span><span class="s">'Z2'</span><span class="p">],</span> <span class="n">cache</span><span class="p">[</span><span class="s">'A2'</span><span class="p">])</span>
    
    <span class="n">dZ2</span> <span class="o">=</span> <span class="n">A2</span> <span class="o">-</span> <span class="n">Y</span>       <span class="c1"># (1, 400)
</span>    <span class="n">dW2</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">m</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">dZ2</span><span class="p">,</span> <span class="n">A1</span><span class="p">.</span><span class="n">T</span><span class="p">)</span>      <span class="c1"># (1, 400) x (400, 4) --&gt; (1, 4)
</span>    <span class="n">db2</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">m</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">dZ2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>       <span class="c1"># (1, 1)
</span>    
    <span class="n">dZ1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W2</span><span class="p">.</span><span class="n">T</span><span class="p">,</span> <span class="n">dZ2</span><span class="p">),</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">np</span><span class="p">.</span><span class="n">power</span><span class="p">(</span><span class="n">A1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>   <span class="c1"># (4, 1) x (1, 400) * (4, 400) --&gt; (4, 400)
</span>    <span class="n">dW1</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">m</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">dZ1</span><span class="p">,</span> <span class="n">X</span><span class="p">.</span><span class="n">T</span><span class="p">)</span>        <span class="c1"># (4, 400) * (400, 2)  --&gt; (4, 2)
</span>    <span class="n">db1</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">m</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">dZ1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>    <span class="c1"># (1, 1) 
</span>    
    <span class="n">grads</span> <span class="o">=</span> <span class="p">{</span><span class="s">'dW1'</span><span class="p">:</span> <span class="n">dW1</span><span class="p">,</span> <span class="s">'dW2'</span><span class="p">:</span> <span class="n">dW2</span><span class="p">,</span> <span class="s">'db1'</span> <span class="p">:</span> <span class="n">db1</span><span class="p">,</span> <span class="s">'db2'</span><span class="p">:</span> <span class="n">db2</span><span class="p">}</span>
    
    <span class="k">return</span> <span class="n">grads</span>
</code></pre></div></div>

<ul>
  <li><strong>Summary</strong>
    <ul>
      <li><img src="https://user-images.githubusercontent.com/92680829/169806728-ad382c6e-eac1-43b6-a7dc-2fa14d4c40d4.png" width="550" /></li>
    </ul>
  </li>
</ul>

<h4 id="update-parameters">Update Parameters</h4>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">update_params</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">grads</span><span class="p">,</span> <span class="n">lr</span> <span class="o">=</span> <span class="mf">1.2</span><span class="p">):</span>
    <span class="n">W1</span><span class="p">,</span> <span class="n">b1</span><span class="p">,</span> <span class="n">W2</span><span class="p">,</span> <span class="n">b2</span> <span class="o">=</span> <span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s">'W1'</span><span class="p">],</span> <span class="n">params</span><span class="p">[</span><span class="s">'b1'</span><span class="p">],</span> <span class="n">params</span><span class="p">[</span><span class="s">'W2'</span><span class="p">],</span> <span class="n">params</span><span class="p">[</span><span class="s">'b2'</span><span class="p">])</span>     
    <span class="n">dW1</span><span class="p">,</span> <span class="n">db1</span><span class="p">,</span> <span class="n">dW2</span><span class="p">,</span> <span class="n">db2</span> <span class="o">=</span> <span class="p">(</span><span class="n">grads</span><span class="p">[</span><span class="s">'dW1'</span><span class="p">],</span> <span class="n">grads</span><span class="p">[</span><span class="s">'db1'</span><span class="p">],</span> <span class="n">grads</span><span class="p">[</span><span class="s">'dW2'</span><span class="p">],</span> <span class="n">grads</span><span class="p">[</span><span class="s">'db2'</span><span class="p">])</span>  
    
    <span class="n">W1</span> <span class="o">-=</span> <span class="n">lr</span><span class="o">*</span><span class="n">dW1</span>   <span class="c1"># (4, 2)
</span>    <span class="n">W2</span> <span class="o">-=</span> <span class="n">lr</span><span class="o">*</span><span class="n">dW2</span>    <span class="c1"># (1, 4)
</span>    <span class="n">b1</span> <span class="o">-=</span> <span class="n">lr</span><span class="o">*</span><span class="n">db1</span>    <span class="c1"># (4, 1)
</span>    <span class="n">b2</span> <span class="o">-=</span> <span class="n">lr</span><span class="o">*</span><span class="n">db2</span>    <span class="c1"># (1, 1)
</span>    
    <span class="n">updated_params</span> <span class="o">=</span> <span class="p">{</span><span class="s">'W1'</span> <span class="p">:</span> <span class="n">W1</span><span class="p">,</span> <span class="s">'b1'</span> <span class="p">:</span> <span class="n">b1</span><span class="p">,</span> <span class="s">'W2'</span> <span class="p">:</span> <span class="n">W2</span><span class="p">,</span> <span class="s">'b2'</span> <span class="p">:</span> <span class="n">b2</span><span class="p">}</span>
    
    <span class="k">return</span> <span class="n">updated_params</span>
</code></pre></div></div>

<h4 id="build-nn-model">Build NN model</h4>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">nn_model</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">nh</span><span class="p">,</span> <span class="n">num_iter</span><span class="p">,</span> <span class="n">print_cost</span><span class="p">):</span>
    <span class="s">"""
    Arguments:
    num_iterations -- Number of iterations in gradient descent loop
    print_cost -- if True, print the cost every 1000 iterations
    
    Returns:
    parameters -- parameters learnt by model (fp -&gt; compute cost &amp; bp -&gt; update)
    """</span>
    
    <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">nx</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">ny</span> <span class="o">=</span> <span class="n">layer_sizes</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
    
    <span class="n">params</span> <span class="o">=</span> <span class="n">initialize_params</span><span class="p">(</span><span class="n">nx</span><span class="p">,</span> <span class="n">nh</span><span class="p">,</span> <span class="n">ny</span><span class="p">)</span>
    <span class="n">min_cost</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s">'inf'</span><span class="p">)</span>
    <span class="n">learning_curve</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_iter</span><span class="p">):</span>    
        <span class="n">cache</span> <span class="o">=</span> <span class="n">fp</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
        <span class="n">A2</span> <span class="o">=</span> <span class="n">cache</span><span class="p">[</span><span class="s">'A2'</span><span class="p">]</span>
        <span class="n">cost</span> <span class="o">=</span> <span class="n">compute_cost</span><span class="p">(</span><span class="n">A2</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
        <span class="n">grads</span> <span class="o">=</span> <span class="n">bp</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">cache</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
        <span class="n">params</span> <span class="o">=</span> <span class="n">update_params</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">grads</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">cost</span> <span class="o">&lt;</span> <span class="n">min_cost</span><span class="p">:</span>
            <span class="n">min_cost</span> <span class="o">=</span> <span class="n">cost</span>
            <span class="n">best_params</span> <span class="o">=</span> <span class="n">params</span>
        
        <span class="k">if</span> <span class="n">print_cost</span> <span class="ow">and</span> <span class="n">i</span><span class="o">%</span><span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">learning_curve</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
            
            <span class="k">if</span> <span class="n">i</span><span class="o">%</span><span class="mi">1000</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">print</span><span class="p">(</span><span class="s">"Cost after iterations {0} : {1}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">cost</span><span class="p">))</span>
                
    <span class="c1">#   print(cost)
</span>    
    <span class="k">return</span> <span class="n">params</span><span class="p">,</span> <span class="n">best_params</span><span class="p">,</span> <span class="n">min_cost</span><span class="p">,</span> <span class="n">learning_curve</span>
    
</code></pre></div></div>

<ul>
  <li>Now Finally, weâ€™ve made our NN model!</li>
  <li>From now on, we will gonna predict the classes of examples (either 0 or 1) using our model</li>
  <li>Decision Rule
    <ul>
      <li><img src="https://user-images.githubusercontent.com/92680829/168468017-a935af58-411e-437b-aef5-ea3adfef107e.png" width="500" /></li>
    </ul>
  </li>
</ul>

<h4 id="predict-classes-of-x">Predict classes of X</h4>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">best_params</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
    <span class="s">"""
    Using the learned parameters, predicts a class for each example in X
    
    Arguments:
    parameters -- python dictionary containing your parameters
    X -- input data of size (n_x, m)
    
    Returns
    predictions -- vector of predictions of our model (red: 0 / blue: 1)
    """</span>
    
    <span class="n">cache</span> <span class="o">=</span> <span class="n">fp</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">best_params</span><span class="p">)</span>
    <span class="n">A2</span> <span class="o">=</span> <span class="n">cache</span><span class="p">[</span><span class="s">'A2'</span><span class="p">]</span>    <span class="c1"># predicted values  (not classes)
</span>    
    <span class="n">preds</span> <span class="o">=</span> <span class="n">A2</span> <span class="o">&gt;</span> <span class="mf">0.5</span>   <span class="c1"># (1, 400)
</span>    
    <span class="k">return</span> <span class="n">preds</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Result 
</span><span class="n">params</span><span class="p">,</span> <span class="n">best_params</span><span class="p">,</span> <span class="n">min_cost</span><span class="p">,</span> <span class="n">learning_curve</span> <span class="o">=</span> <span class="n">nn_model</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">10000</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="c1"># plt.figure(figsize=(8, 5))
# plt.axis([0, 1000, 0, max(learning_curve)])        # [xmin, xmax, ymin, ymax]
</span><span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">learning_curve</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Iterations"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Cost"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Learning Curve (Cost by Iterations)"</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
</code></pre></div></div>

<p><img width="460" alt="image" src="https://user-images.githubusercontent.com/92680829/168481446-71a848cf-cc9b-4f58-94d8-0d3f28c09afa.png" /></p>

<p><img width="525" alt="image" src="https://user-images.githubusercontent.com/92680829/168481497-1428fc0e-5016-48fc-a695-8d78f7ce9442.png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># x : comes with shape (400, 2)
</span><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plot_decision_boundary</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span> <span class="p">:</span> <span class="n">predict</span><span class="p">(</span><span class="n">best_params</span><span class="p">,</span> <span class="n">x</span><span class="p">.</span><span class="n">T</span><span class="p">),</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="s">"Neural Network Model with a Single Hidden Layer"</span><span class="p">)</span>
</code></pre></div></div>
<p><img width="580" alt="image" src="https://user-images.githubusercontent.com/92680829/168481516-55e35ec9-5cf6-4aac-b0ca-ca2f30266ecb.png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">accuracy_score</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">nh</span><span class="p">):</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">Y</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">error</span> <span class="o">=</span> <span class="nb">float</span><span class="p">((</span><span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">Y</span><span class="p">,</span> <span class="n">preds</span><span class="p">.</span><span class="n">T</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="mi">1</span><span class="o">-</span><span class="n">preds</span><span class="p">.</span><span class="n">T</span><span class="p">))</span><span class="o">/</span><span class="n">m</span><span class="p">)</span>   
    <span class="c1"># same as np.sum(np.multiply(1-Y, preds) + np.multiply(Y, 1-preds))/m
</span>    <span class="k">print</span><span class="p">(</span><span class="s">"Accuracy with Neural Network with 1 Hidden Layer with {0} Units: {1} %"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">nh</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">error</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
    
    <span class="k">return</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">error</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">_</span><span class="p">,</span> <span class="n">best_params</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">nn_model</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">10000</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">preds</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">best_params</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="n">accuracy_score</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
</code></pre></div></div>
<p><img width="341" alt="image" src="https://user-images.githubusercontent.com/92680829/168481532-09476a66-87ac-47af-95f1-91151179b55f.png" /></p>

<ul>
  <li>From our NN model (1 hidden layer with 4 units), weâ€™ve just gained 90% accuracy</li>
  <li>Previously, accuracy from Logistic Regression Classifier was 47%</li>
  <li>Now you can see NN with only one hidden layer can outperform Logistic regression</li>
  <li>Our NN model has learnt the leaf patterns of the flower, which shows NN can learn even highly non-linear decision boundaries, unlike logistic regression.</li>
</ul>

<h2 id="5-compare-accuracy-of-nn-with-different-unit-sizes-of-hidden-layer"><strong>5. Compare Accuracy of NN with Different Unit Sizes of Hidden Layer</strong></h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">24</span><span class="p">))</span>
<span class="n">h_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">]</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">nh</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">h_sizes</span><span class="p">):</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">best_params</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">nn_model</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">nh</span><span class="p">,</span> <span class="mi">10000</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">best_params</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
    <span class="n">plot_decision_boundary</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span> <span class="p">:</span> <span class="n">predict</span><span class="p">(</span><span class="n">best_params</span><span class="p">,</span> <span class="n">x</span><span class="p">.</span><span class="n">T</span><span class="p">),</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="s">"Hidden Units {0}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">nh</span><span class="p">))</span>
    <span class="n">accuracy_score</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">nh</span><span class="p">)</span>
</code></pre></div></div>

<p><img width="647" alt="image" src="https://user-images.githubusercontent.com/92680829/168481546-e2b19f97-afe7-4dea-bad2-e79c3430b2ca.png" /></p>

<p><img width="630" alt="image" src="https://user-images.githubusercontent.com/92680829/168481570-724bce8a-e398-40e7-aab0-0bbf913bbe5b.png" /></p>

<h3 id="interpretations-"><strong>Interpretations :</strong></h3>
<ul>
  <li>The larger models (with more hidden units) are able to fit the training set better, until eventually the largest models overfit the data.</li>
  <li>The best hidden layer size seems to be around nh 8.</li>
  <li>Indeed, values greater than 8 seem to incur noticable overfitting as shown in decision boundary contour plot.</li>
  <li>You will also learn later about regularization, which lets you use very large models (such as n_h = 50) without much overfitting.</li>
</ul>

<h2 id="6-performance-on-other-datasets"><strong>6. Performance on Other Datasets</strong></h2>
<ul>
  <li>Now, letâ€™s test our model performance on other 4 datasets</li>
  <li>Unit size of 1 Hidden layer will be fixed as 8, which was figured as best unit size that prevents overfitting</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">datasets</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
<span class="n">datasets</span><span class="p">[</span><span class="s">'noisy_circles'</span><span class="p">],</span> <span class="n">datasets</span><span class="p">[</span><span class="s">'noisy_moons'</span><span class="p">],</span> <span class="n">datasets</span><span class="p">[</span><span class="s">'blobs'</span><span class="p">],</span> <span class="n">datasets</span><span class="p">[</span><span class="s">'gaussian_quantiles'</span><span class="p">],</span> <span class="n">_</span> <span class="o">=</span> <span class="n">load_extra_datasets</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">accuracy_score_2</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">d</span><span class="p">):</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">Y</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">error</span> <span class="o">=</span> <span class="nb">float</span><span class="p">((</span><span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">Y</span><span class="p">,</span> <span class="n">preds</span><span class="p">.</span><span class="n">T</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="mi">1</span><span class="o">-</span><span class="n">preds</span><span class="p">.</span><span class="n">T</span><span class="p">))</span><span class="o">/</span><span class="n">m</span><span class="p">)</span>   
    <span class="c1"># same as np.sum(np.multiply(1-Y, preds) + np.multiply(Y, 1-preds))/m
</span>    <span class="k">print</span><span class="p">(</span><span class="s">"Accuracy for Dataset &lt;{0}&gt; with Unit Size 8 : {1}%"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">error</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
    
    <span class="k">return</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">error</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">24</span><span class="p">))</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">datasets</span><span class="p">.</span><span class="n">keys</span><span class="p">()):</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">[</span><span class="n">d</span><span class="p">]</span>
    <span class="c1"># print(X.shape, Y.shape)
</span>    <span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">T</span><span class="p">,</span> <span class="n">Y</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">Y</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">d</span> <span class="o">==</span> <span class="s">'blobs'</span><span class="p">:</span>
        <span class="n">Y</span> <span class="o">=</span> <span class="n">Y</span><span class="o">%</span><span class="mi">2</span>
    
    <span class="n">_</span><span class="p">,</span> <span class="n">best_params</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">nn_model</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">10000</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">best_params</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
    <span class="n">plot_decision_boundary</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span> <span class="p">:</span> <span class="n">predict</span><span class="p">(</span><span class="n">best_params</span><span class="p">,</span> <span class="n">x</span><span class="p">.</span><span class="n">T</span><span class="p">),</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="s">"Datasets : {0} with Unit size 8"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">d</span><span class="p">))</span>
    <span class="n">accuracy_score_2</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span>
</code></pre></div></div>
<p><img width="617" alt="image" src="https://user-images.githubusercontent.com/92680829/168481747-301e12ff-4e7d-4d1f-86b0-503ee1a4b2ec.png" /></p>

<p><img width="617" alt="image" src="https://user-images.githubusercontent.com/92680829/168481765-a62b3c56-f302-4f68-8996-c5798073a4a8.png" /></p>

<ul>
  <li>Performance of our NN model quite differs by the datasets</li>
  <li>But, definitely can tell that our model can learn highly non-linear, complex decision boundaries with pretty fine accuracy</li>
</ul>
:ET