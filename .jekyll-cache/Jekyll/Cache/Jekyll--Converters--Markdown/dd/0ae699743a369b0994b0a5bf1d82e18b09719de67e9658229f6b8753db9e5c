I"3
<h2 id="outlines"><strong>Outlines</strong></h2>
<ul>
  <li><a href="#references"><strong>References</strong></a></li>
  <li><a href="#mobilenet-v1"><strong>MobileNet V1</strong></a>
    <ul>
      <li><a href="#depthwise-separable-convolution"><strong>Depthwise Separable Convolution</strong></a></li>
      <li><a href="#comparison-of-computational-cost"><strong>Comparison of Computational Cost</strong></a></li>
      <li><a href="#trade-off--accuracy-vs-complexity"><strong>Trade-Off : Accuracy vs Complexity</strong></a></li>
      <li><a href="#mobilenet-architecture"><strong>MobileNet Architecture</strong></a></li>
      <li><a href="#mobilenet-v1-comparison-to-other-models"><strong>MobileNet V1 Comparison to Other Models</strong></a></li>
    </ul>
  </li>
  <li><a href="#model-summary"><strong>Model Summary</strong></a></li>
  <li><a href="#other-types-of-convolution"><strong>Other Types of Convolution</strong></a></li>
  <li><a href="#other-types-of-convolution"><strong>Other Types of Convolution</strong></a></li>
  <li><a href="#other-types-of-convolution"><strong>Other Types of Convolution</strong></a></li>
  <li><a href="#other-types-of-convolution"><strong>Other Types of Convolution</strong></a></li>
  <li><a href="#other-types-of-convolution"><strong>Other Types of Convolution</strong></a></li>
  <li><a href="#other-types-of-convolution"><strong>Other Types of Convolution</strong></a></li>
  <li><a href="#other-types-of-convolution"><strong>Other Types of Convolution</strong></a></li>
  <li><a href="#other-types-of-convolution"><strong>Other Types of Convolution</strong></a></li>
  <li><a href="#other-types-of-convolution"><strong>Other Types of Convolution</strong></a></li>
  <li><a href="#other-types-of-convolution"><strong>Other Types of Convolution</strong></a></li>
</ul>

<p><br /></p>

<h2 id="references"><strong>References</strong></h2>

<p><br /></p>

<ul>
  <li><a href="https://arxiv.org/abs/1704.04861" target="_blank">MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications, Andrew Howard, (2017)</a></li>
  <li><a href="https://arxiv.org/abs/1801.04381" target="_blank">MobileNetV2: Inverted Residuals and Linear Bottlenecks, Mark Sandler, (2019)</a></li>
  <li><a href="https://arxiv.org/abs/1905.02244" target="_blank">Searching for MobileNetV3, Andrew Howard, (2019)</a></li>
  <li><a href="https://hyukppen.modoo.at/?link=5db82s6p" target="_blank">https://hyukppen.modoo.at/?link=5db82s6p</a></li>
</ul>

<p><br /></p>

<h2 id="mobilenet-v1"><strong>MobileNet V1</strong></h2>

<p><br /></p>

<ul>
  <li>For resource constrained environment such as mobile devices, it is very important to build computationally efficient networks.</li>
  <li>MobileNet v1 efficiently trade-off between efficiency and accuracy by adopting depthwise separable convolutional filters.</li>
</ul>

<p><br /></p>

<h3 id="depthwise-separable-convolution"><strong>Depthwise Separable Convolution</strong></h3>

<p><br /></p>

<p> <img src="https://github.com/SuminizZ/Physics/assets/92680829/421bbbfb-1e45-42f0-8993-b4ac0833b506" width="410" /></p>

<p><br /></p>

<ol>
  <li><strong>Depthwise Convolution</strong>
    <ul>
      <li>Idential to the grouped convolution with cardinality equal to total channel size.</li>
      <li>Only performs spatial convolution where each channel of the input requires a single filter and concatenates the resultant feature maps.</li>
      <li>Each feature map contains spatial representation within one chanenl.</li>
      <li>This reduces the network complexities, as each filter is only responsible for convolving with its corresponding input channel.</li>
    </ul>
  </li>
  <li><strong>Separable Convolution</strong>
    <ul>
      <li>Use 1x1 convolution filter to perform channel-wise convolution and linearly combines each input channel into different sets of feature maps.</li>
    </ul>
  </li>
</ol>

<ul>
  <li>Two of convolutions combined can perform roughly identical operation as traditional convolution with no significant decrease in accuracy, but dramatically reduces the computational cost.</li>
</ul>

<p><br /></p>

<h3 id="comparison-of-computational-cost"><strong>Comparison of Computational Cost</strong></h3>

<p><br /></p>

<p>  <img src="https://github.com/SuminizZ/Physics/assets/92680829/8157ce73-23a0-4378-a942-cc3ae2dc534d" width="380" /></p>

<p><br /></p>

<ul>
  <li>H, W : input shape per channel</li>
  <li>C : the number of input channels</li>
  <li>F : the number of output features</li>
  <li>K : kernel size of each filter</li>
  <li><strong>standard convolution</strong>
    <ul>
      <li>H x W x K x K x C x F</li>
    </ul>
  </li>
  <li><strong>depthwise separable convolution</strong>
    <ul>
      <li>H x W x K x K x C + H x W x C x F</li>
    </ul>
  </li>
  <li>H x W x K x K x C + H x W x C x F / (H x W x K x K x C x F)
    <ul>
      <li>1/F + 1/K^2</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h3 id="trade-off--accuracy-vs-complexity"><strong>Trade-Off : Accuracy vs Complexity</strong></h3>

<p><br /></p>

<p>  <img src="https://github.com/SuminizZ/Physics/assets/92680829/18429f53-cc02-49d9-990d-246ddd65e8f6" width="400" /></p>

<p><br /></p>

<ol>
  <li><strong>Width Multipliers</strong>
    <ul>
      <li>$\alpha \in (0, 1]$</li>
      <li>simple hyperparameter $\large \alpha$ to regulate the width of the networks</li>
      <li>multiplied to the number of channel at each layer</li>
    </ul>
  </li>
  <li><strong>Resolution Multipliers</strong>
    <ul>
      <li>$\rho \in (0, 1]$</li>
      <li>adjust the resolution (size of input)</li>
      <li>affects the representation</li>
      <li>no change in the number of parameters</li>
    </ul>
  </li>
</ol>

<ul>
  <li>Can make faster but weaker model by simply applying a few hyperparameters. Setting $\large \alpha$ and $\large \rho$ as 1 equals to a baseline.</li>
</ul>

<p><br /></p>

<p>  <img src="https://github.com/SuminizZ/Physics/assets/92680829/3c1f9959-67e2-4cee-9295-f4fc60ac689c" width="400" /></p>

<p><br /></p>

<h3 id="mobilenet-architecture"><strong>MobileNet Architecture</strong></h3>

<p><br /></p>

<p>  <img src="https://github.com/SuminizZ/Physics/assets/92680829/c3ebef6a-4edf-405b-82dc-499747b54e1c" width="480" /></p>

<p><br /></p>

<h3 id="mobilenet-v1-comparison-to-other-models"><strong>MobileNet V1 Comparison to Other Models</strong></h3>

<p><br /></p>

<p>  <img src="https://github.com/SuminizZ/Physics/assets/92680829/739ef37d-0c41-4f5c-b63b-8b35d7a60c6a" width="400" /></p>

<p><br /></p>

<ul>
  <li>Achieves higher accuracy with much fewer paramters, indicating efficient use of resources in MobileNet architecture.</li>
</ul>

<p><br /></p>

<hr />

<p><br /></p>

<h2 id="mobilenet-v2"><strong>MobileNet V2</strong></h2>

<p><br /></p>

<h3 id="relu-causes-manifold-collapse"><strong>ReLU Causes Manifold Collapse</strong></h3>

<p><br /></p>

<ul>
  <li>
    <p>While ReLU is effective in promoting non-linearity and alleviating the vanishing gradient problem, it can cause the loss of information encoded in negative values as it sets the activations as zero except positive values.</p>
  </li>
  <li>
    <p>This becomes signified when the relu is applied on the data compressed in dimensionality.</p>
  </li>
  <li>
    <p><strong>Manifold in Low-Dimensional Subspace of the Activation Space</strong></p>

    <ul>
      <li>Assuming that manifold in neural networks is embedded in low-dimensional subspaces, ReLU activation can maintain that input manifold as the type of the activation it performs is limited to linear transformation (mulitply 1 if positive, 0 if negative).</li>
      <li>But the preservation of input manifold can only be possible if the dimensionality of activation space is much higher than that of the manifold.Otherwise, entire deletion of information embedded in negative values using ReLU results in significant distortion of the manifold (Collapsed manifold)</li>
    </ul>
  </li>
</ul>

<p>   <strong>Figure 1. ReLU transformation of low-dimensional manifolds into n-dimensional output</strong></p>

<p>   <img src="https://github.com/SuminizZ/Physics/assets/92680829/7320b284-ffe7-4bdf-b218-1ec5727a8274" width="600" /></p>

<p><br /></p>

<ul>
  <li>Input : initial input where low-dimensional manifold is embedded</li>
  <li>output dimension ‘n’ increases from 2 to 30</li>
  <li><strong>Operations</strong>
    <ol>
      <li>embed into n-dimensional space with random matrix $\large T$ (2xn)</li>
      <li>follwed by ReLU transformation</li>
      <li>restore the data into its original dimensionality with $\large T^{-1}$</li>
      <li>plot the data to see if ReLU transformation preserve the manifold or not.</li>
    </ol>
  </li>
  <li>Can observe expansion into higher dimensionality before ReLU being applied shows better maintenance of input manifold. This mean that input manifold embedded into much lower-dimensional subspace of activation space can be preserved after ReLU transformation.</li>
</ul>

<p><br /></p>

<h3 id="inverted-residual-block"><strong>Inverted Residual Block</strong></h3>

<p><br /></p>

<ul>
  <li>To tackle this issue, authors developed a unique block called <strong>“Inverted Residual Bottleneck”</strong> where the residual learning undergoes an <strong>expansion layer</strong> before entering into ReLU activation and then spatially filtered with a <strong>lightweight depthwise 3x3 convolution</strong> follwed by <strong>1x1 pointwise convolution with linear activation (no ReLU)</strong>. Skip connection then is added to final resultant output of pointwise convolution and <strong>no ReLU activation applied after concatenation</strong>. This is the exact opposite of how typical bottleneck structure as used in MobileNet V1 operates.</li>
</ul>

<p><br /></p>

<p>   <strong>Figure 3. Comparison between original residual block in V1 and inverted residual block in V2</strong></p>

<p>   <img src="https://github.com/SuminizZ/Physics/assets/92680829/5b73b94a-164d-4fbb-af3a-ad58d53fc93b" width="640" /></p>

<p>   <img src="https://github.com/SuminizZ/Physics/assets/92680829/a55aa2c4-3c3f-4598-a8fb-847389fe0440" width="500" /></p>

<p><br /></p>

<ul>
  <li>
    <p>This enables implementing non-linearity with ReLU without losing input manifold informaiton.</p>
  </li>
  <li>
    <p>Linear activation adopted here plays a crucial as it prevents non-linearities from destroying too much information, resulting in better model performance.</p>
  </li>
</ul>

<p>   <strong>Figure 6. The impact of non-linearities and various
types of shortcut connections</strong></p>

<p>   <img src="https://github.com/SuminizZ/Physics/assets/92680829/775c754f-3d15-41d1-9c8c-a9d2c516f2aa" width="550" /></p>

<p><br /></p>

<p>   <strong>Table 1. Architecture of Inveted Bottleneck Residual block used in MobileNet V2</strong></p>

<p>   <img src="https://github.com/SuminizZ/Physics/assets/92680829/ea78ef5b-cd29-481d-bce9-38d9537487a3" width="480" /> <br /></p>

<ul>
  <li>
    <p>can see MobileNet V2 has clear computaitonal advantages over other networks with the lowest max number of memory.</p>
  </li>
  <li><strong>ReLU6 = min(max(x, 0), 6)</strong>
    <ul>
      <li>clamp the maximum value as 6</li>
      <li>increases non-linearity</li>
      <li>computational stability and efficient use of memory resources</li>
    </ul>
  </li>
  <li><strong>Residual connection</strong> only used for the block whose input shape equlas to output shape.</li>
</ul>

<p><br /></p>

<h3 id="computational-advantage-of-mobilenet-v2-over-v1"><strong>Computational Advantage of MobileNet V2 over V1</strong></h3>

<p><br /></p>

<ul>
  <li>Computational cost of <strong>depthwise (DW) vs pointwise (PW)</strong> layer
    <ul>
      <li>using 3x3 convolution to input of 64 channel with 128 output feature maps</li>
      <li>DW : 3 x 3 x 64</li>
      <li>PW : 1 x 1 x 64 x 128</li>
      <li>Typically, PW tends to require greater computations compared to DW</li>
      <li>New inverted residuals block takes advantage of this by expanding DW layer and narrowing down the PW layer.</li>
    </ul>
  </li>
  <li><strong>Comparison : V1 vs V2</strong></li>
  <li><strong>Example</strong> <br /></li>
</ul>

<p>    <img src="https://github.com/SuminizZ/Physics/assets/92680829/899da86f-78ee-4528-a121-19feb0b793a3" width="600" /></p>

<ul>
  <li>Inverted Residual Block (V2) : (1 x 1 x 24 x 144) + (3 x 3 x 144) + (1 x 1 x 144 x 24) = 8,208</li>
  <li>
    <p>Residuals Block (V1) : (3 x 3 x 144) + (144 x 144) = 22,032</p>
  </li>
  <li>Inverted residuals block of MobileNet V2 has rougly about 1/3 computations required for MobileNet V1</li>
</ul>

<p>   <strong>Table 3. The max number of channels/memory (in Kb) for different network architectures</strong></p>

<p>      <img src="https://github.com/SuminizZ/Physics/assets/92680829/08343946-583a-43e3-91f6-803a2534aed9" width="450" /></p>

<p>   <strong>Table 4. Performance on ImageNet for different architectures</strong></p>

<p>      <img src="https://github.com/SuminizZ/Physics/assets/92680829/08343946-583a-43e3-91f6-803a2534aed9" width="450" /></p>

<p><br /></p>

<h3 id="mobilenet-v2-architecture"><strong>MobileNet V2 Architecture</strong></h3>

<p><br /></p>

<p> <img src="https://github.com/SuminizZ/Physics/assets/92680829/bb6a7863-d3d5-4273-b4f1-4311d67f1d3f" width="440" /></p>

<h2 id="mobilenet-v3"><strong>MobileNet V3</strong></h2>

<p><br /></p>

<h3 id="1-adding-squeeze-and-excitation-layer"><strong>1. Adding Squeeze and Excitation Layer</strong></h3>

<ul>
  <li>Squeeze-Excitation (SE) module
    <ul>
      <li>
        <p>can learn interdependent importance between features (channels)</p>
      </li>
      <li>
        <p>Squeeze : GAP into 1x1xC (channels)</p>
      </li>
      <li>
        <p>Excitation : 2 steps FC layer to get stronger representation for important feature or pattern</p>
      </li>
    </ul>
  </li>
</ul>

<p>   <strong>Squeeze-Excitation</strong></p>

<p>      <img src="https://github.com/SuminizZ/Physics/assets/92680829/f19d8cfc-7380-4728-bfab-5ff4c9261c05" width="380" /></p>

<p>   <strong>MobileNet V2 + SE module</strong></p>

<p>      <img src="https://github.com/SuminizZ/Physics/assets/92680829/2fa3a0af-da40-4bac-bf92-74fe7c7f9fc1" width="580" /></p>

<p><br /></p>

<ul>
  <li>being interposed between 3x3 depthwise convolution and 1x1 pointwise convolution</li>
</ul>

<p><br /></p>

<h3 id="2-use-of-new-non-linearity--hard-sigmoind--hard-swish"><strong>2. Use of New Non-Linearity : Hard Sigmoind &amp; Hard Swish</strong></h3>

<ul>
  <li>
    <p>Sigmoid = $\large \frac{1}{1\,+\,e^{-x}}$</p>
  </li>
  <li>
    <p>Swish = $\large x\times\,sigmoid(x)$</p>
  </li>
  <li>
    <p>Hard Sigmoid = $\large \frac{ReLU6\,(x\,+\,3)}{6}$</p>
  </li>
  <li>
    <p>Hard Swish = $\large x\times\, \frac{ReLU6\,(x\,+\,3)}{6}$</p>
  </li>
</ul>

<p>  <strong>Figure 6</strong></p>

<p>  <img src="https://github.com/SuminizZ/Physics/assets/92680829/bf8e1578-7937-42d6-8505-5154114162af" width="580" /></p>

<ul>
  <li>
    <p>compuationally stable with no possible precision error caused by different implementations of approximate sigmoid function</p>
  </li>
  <li>
    <p>ReLU6 as piece-wise function unlike sigmoid significanlty reduces memory use with no discernible difference in accuracy</p>
  </li>
</ul>

<p><br /></p>

<h3 id="3-redesigning-expensive-layers"><strong>3. Redesigning Expensive Layers</strong></h3>

<p><br /></p>

<p>  <strong>Figure 5. : Comparision of original last stage and efficient last stage</strong></p>

<p>  <img src="https://github.com/SuminizZ/Physics/assets/92680829/7548afe8-0f8b-4a9c-b045-622233588b20" width="580" /></p>

<p><br /></p>

<ul>
  <li><strong>Last feature extraction layer</strong>
    <ul>
      <li>original : <strong>1x1 conv - BN - H-swish</strong> stage that expands the feature from 320 to 1280 to 7x7 resoultion input
        <ul>
          <li>computations : 7 x 7 x 320 x 1280</li>
          <li>greatly increases the computations and thus, latency</li>
        </ul>
      </li>
      <li>modified : move the feature extraction stage past the final average pooling layer
        <ul>
          <li>applies <strong>1x1 conv - H-swish</strong> to 1x1x960 input (instead of 7x7 spatial resolution) and creates output with 1280 features</li>
          <li>computations : 1 x 1 x 960 x 1280</li>
        </ul>
      </li>
      <li>The efficient last stage reduces the latency by 7 milliseconds which is 11% of the running time and reduces the number of operations by 30 millions MAdds with almost no loss of accuracy</li>
    </ul>
  </li>
  <li>
    <p><strong>Replace ReLU6 -&gt; H-Swish non-linearity</strong></p>

    <ul>
      <li>
        <p>Use dfferent type of non-linearity to reduce redundancy</p>
      </li>
      <li>
        <p>As a result, able to reduce the number of filters to 16 while maintaining the same accuracy as 32 filters using either ReLU or swish. This saves an additional 2 milliseconds and 10 million MAdds.</p>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h3 id="mobilenet-v3-architecture-small--large"><strong>MobileNet V3 Architecture (Small &amp; Large)</strong></h3>

<p><br /></p>

<ul>
  <li>Found by <strong>1. platform-aware NAS for block-wise search</strong> and <strong>2. NetAdapt for layer-wise search</strong>
    <ul>
      <li>
        <p>find the one that maximizes the ratio of accuracy change to latency change (maximizes the trade-off slope : $Δ$ accuracy /  $Δ$ latency)</p>
      </li>
      <li>
        <p>proposal type</p>
        <ul>
          <li>size of expansion layer</li>
          <li>reduce the bottleneck in all blocks using same bottleneck size to keep residual-connections</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<p>  <strong>Table 1. :  Specification for MobileNetV3-Large</strong></p>

<p>  <img src="https://github.com/SuminizZ/Physics/assets/92680829/212f2343-c8bd-4e60-ad8e-e558fb9fc19a" width="500" /></p>

<p><br /></p>

<p>  <strong>Table 2. :  Specification for MobileNetV3-Small</strong></p>

<p>  <img src="https://github.com/SuminizZ/Physics/assets/92680829/212f2343-c8bd-4e60-ad8e-e558fb9fc19a" width="500" /></p>

<p><br /></p>

<ul>
  <li>All channels are divisible by 8 for computational efficiency</li>
</ul>

<hr />

<h2 id="implementation-with-pytorch"><strong>Implementation with PyTorch</strong></h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">get_divisible</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">divider</span><span class="p">):</span>
    <span class="n">new_v</span> <span class="o">=</span> <span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">v</span> <span class="o">+</span> <span class="n">divider</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span><span class="o">//</span><span class="n">divider</span><span class="p">)</span><span class="o">*</span><span class="n">divider</span>
    <span class="k">if</span> <span class="n">new_v</span> <span class="o">&lt;</span> <span class="mf">0.9</span><span class="o">*</span><span class="n">v</span><span class="p">:</span>
        <span class="n">new_v</span> <span class="o">+=</span> <span class="n">divider</span>
    <span class="k">return</span> <span class="nb">max</span><span class="p">(</span><span class="n">new_v</span><span class="p">,</span> <span class="n">divider</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">Squeeze_Excite</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">r</span><span class="o">=</span><span class="mi">4</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">squeeze</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">AdaptiveAvgPool2d</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">excitation</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">channels</span><span class="p">,</span> <span class="n">channels</span><span class="o">//</span><span class="n">r</span><span class="p">),</span>
                                        <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
                                        <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">channels</span><span class="o">//</span><span class="n">r</span><span class="p">,</span> <span class="n">channels</span><span class="p">),</span>
                                        <span class="n">nn</span><span class="p">.</span><span class="n">Hardsigmoid</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">se</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">se</span> <span class="o">=</span> <span class="n">se</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">se</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">se</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">excitation</span><span class="p">(</span><span class="n">se</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">*=</span> <span class="n">se</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">).</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>


<span class="k">class</span> <span class="nc">InvResBlock</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">exp_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">se</span><span class="p">,</span> <span class="n">nl</span><span class="p">,</span> <span class="n">s</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">se</span> <span class="o">=</span> <span class="n">se</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">skip_connect</span> <span class="o">=</span> <span class="bp">True</span> <span class="k">if</span> <span class="n">s</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">in_channels</span> <span class="o">==</span> <span class="n">out_channels</span> <span class="k">else</span> <span class="bp">False</span>
        <span class="n">non_linearity</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="k">if</span> <span class="n">nl</span><span class="o">==</span><span class="s">'relu'</span> <span class="k">else</span> <span class="n">nn</span><span class="p">.</span><span class="n">Hardswish</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="n">in_channels</span> <span class="o">!=</span> <span class="n">exp_channels</span><span class="p">:</span>
            <span class="n">layers</span> <span class="o">+=</span> <span class="p">[</span><span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">exp_channels</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">),</span>
                                     <span class="n">nn</span><span class="p">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">exp_channels</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.99</span><span class="p">),</span>
                                     <span class="n">non_linearity</span><span class="p">)]</span>

        <span class="n">layers</span> <span class="o">+=</span> <span class="p">[</span><span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">exp_channels</span><span class="p">,</span> <span class="n">exp_channels</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">s</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="n">k</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">//</span><span class="mi">2</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="n">exp_channels</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">),</span>
                                 <span class="n">nn</span><span class="p">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">exp_channels</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.99</span><span class="p">),</span>
                                 <span class="n">non_linearity</span><span class="p">)]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">se</span><span class="p">:</span>
            <span class="n">layers</span> <span class="o">+=</span> <span class="p">[</span><span class="n">Squeeze_Excite</span><span class="p">(</span><span class="n">exp_channels</span><span class="p">)]</span>
        <span class="n">layers</span> <span class="o">+=</span> <span class="p">[</span><span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">exp_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">),</span>
                                 <span class="n">nn</span><span class="p">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.99</span><span class="p">))]</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">residual_x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">layers</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">skip_connect</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="n">residual_x</span>
        <span class="k">return</span> <span class="n">residual_x</span>


<span class="k">class</span> <span class="nc">MobileNetV3</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">cfgs</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="n">zero_init_residual</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">width_exp</span><span class="o">=</span><span class="mf">1.</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">),</span>
                                    <span class="n">nn</span><span class="p">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.99</span><span class="p">),</span>
                                    <span class="n">nn</span><span class="p">.</span><span class="n">Hardswish</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
        <span class="n">in_channels</span> <span class="o">=</span> <span class="mi">16</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">fc_out</span> <span class="o">=</span> <span class="n">cfgs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">exp_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">se</span><span class="p">,</span> <span class="n">nl</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">cfgs</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]:</span>
            <span class="n">layers</span> <span class="o">+=</span> <span class="p">[</span><span class="n">InvResBlock</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">get_divisible</span><span class="p">(</span><span class="n">exp_channels</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span> <span class="n">get_divisible</span><span class="p">(</span><span class="n">out_channels</span><span class="o">*</span><span class="n">width_exp</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span> <span class="n">se</span><span class="p">,</span> <span class="n">nl</span><span class="p">,</span> <span class="n">s</span><span class="p">)]</span>
            <span class="n">in_channels</span> <span class="o">=</span> <span class="n">get_divisible</span><span class="p">(</span><span class="n">out_channels</span><span class="o">*</span><span class="n">width_exp</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">blocks</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>

        <span class="n">k</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">se</span><span class="p">,</span> <span class="n">nl</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="n">cfgs</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
        <span class="n">non_linearity</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="k">if</span> <span class="n">nl</span><span class="o">==</span><span class="s">'relu'</span> <span class="k">else</span> <span class="n">nn</span><span class="p">.</span><span class="n">Hardswish</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">se</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">se_block</span> <span class="o">=</span> <span class="n">Squeeze_Excite</span><span class="p">(</span><span class="n">out_channels</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">last_conv</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">),</span>
                                       <span class="n">nn</span><span class="p">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">out_channels</span><span class="p">),</span>
                                       <span class="n">non_linearity</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">gap</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">AdaptiveAvgPool2d</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">fc_out</span><span class="p">),</span>
                                        <span class="n">nn</span><span class="p">.</span><span class="n">Hardswish</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
                                        <span class="n">nn</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
                                        <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">fc_out</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">))</span>

        <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">modules</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">):</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">init</span><span class="p">.</span><span class="n">kaiming_normal_</span><span class="p">(</span><span class="n">m</span><span class="p">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s">"fan_out"</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">m</span><span class="p">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
                    <span class="n">nn</span><span class="p">.</span><span class="n">init</span><span class="p">.</span><span class="n">zeros_</span><span class="p">(</span><span class="n">m</span><span class="p">.</span><span class="n">bias</span><span class="p">)</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="p">.</span><span class="n">BatchNorm2d</span><span class="p">):</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">init</span><span class="p">.</span><span class="n">ones_</span><span class="p">(</span><span class="n">m</span><span class="p">.</span><span class="n">weight</span><span class="p">)</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">init</span><span class="p">.</span><span class="n">zeros_</span><span class="p">(</span><span class="n">m</span><span class="p">.</span><span class="n">bias</span><span class="p">)</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">):</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">init</span><span class="p">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">m</span><span class="p">.</span><span class="n">weight</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">)</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">init</span><span class="p">.</span><span class="n">zeros_</span><span class="p">(</span><span class="n">m</span><span class="p">.</span><span class="n">bias</span><span class="p">)</span>


    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">blocks</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">last_conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">se</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">se_block</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">gap</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">start_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>


<span class="k">class</span> <span class="nc">Config</span><span class="p">():</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">large</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># kernel, exp, out, se, nl, s
</span>        <span class="n">cfgs</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="bp">False</span><span class="p">,</span> <span class="s">'relu'</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">24</span><span class="p">,</span> <span class="bp">False</span><span class="p">,</span> <span class="s">'relu'</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
                <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">72</span><span class="p">,</span> <span class="mi">24</span><span class="p">,</span> <span class="bp">False</span><span class="p">,</span> <span class="s">'relu'</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">72</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="bp">True</span><span class="p">,</span> <span class="s">'relu'</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
                <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">120</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="bp">True</span><span class="p">,</span> <span class="s">'relu'</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">120</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="bp">True</span><span class="p">,</span> <span class="s">'relu'</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">240</span><span class="p">,</span> <span class="mi">80</span><span class="p">,</span> <span class="bp">False</span><span class="p">,</span> <span class="s">'hs'</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
                <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">80</span><span class="p">,</span> <span class="bp">False</span><span class="p">,</span> <span class="s">'hs'</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">184</span><span class="p">,</span> <span class="mi">80</span><span class="p">,</span> <span class="bp">False</span><span class="p">,</span> <span class="s">'hs'</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">184</span><span class="p">,</span> <span class="mi">80</span><span class="p">,</span> <span class="bp">False</span><span class="p">,</span> <span class="s">'hs'</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">480</span><span class="p">,</span> <span class="mi">112</span><span class="p">,</span> <span class="bp">True</span><span class="p">,</span> <span class="s">'hs'</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">672</span><span class="p">,</span> <span class="mi">112</span><span class="p">,</span> <span class="bp">True</span><span class="p">,</span> <span class="s">'hs'</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">672</span><span class="p">,</span> <span class="mi">160</span><span class="p">,</span> <span class="bp">True</span><span class="p">,</span> <span class="s">'hs'</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
                <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">960</span><span class="p">,</span> <span class="mi">160</span><span class="p">,</span> <span class="bp">True</span><span class="p">,</span> <span class="s">'hs'</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">960</span><span class="p">,</span> <span class="mi">160</span><span class="p">,</span> <span class="bp">True</span><span class="p">,</span> <span class="s">'hs'</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="mi">960</span><span class="p">,</span> <span class="bp">False</span><span class="p">,</span> <span class="s">'hs'</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                <span class="mi">1280</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">cfgs</span>

    <span class="k">def</span> <span class="nf">small</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">cfgs</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="bp">True</span><span class="p">,</span> <span class="s">'relu'</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
                <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">72</span><span class="p">,</span> <span class="mi">24</span><span class="p">,</span> <span class="bp">False</span><span class="p">,</span> <span class="s">'relu'</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
                <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">88</span><span class="p">,</span> <span class="mi">24</span><span class="p">,</span> <span class="bp">False</span><span class="p">,</span> <span class="s">'relu'</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">96</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="bp">True</span><span class="p">,</span> <span class="s">'hs'</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
                <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">240</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="bp">True</span><span class="p">,</span> <span class="s">'hs'</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">240</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="bp">True</span><span class="p">,</span> <span class="s">'hs'</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">120</span><span class="p">,</span> <span class="mi">48</span><span class="p">,</span> <span class="bp">True</span><span class="p">,</span> <span class="s">'hs'</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">144</span><span class="p">,</span> <span class="mi">48</span><span class="p">,</span> <span class="bp">True</span><span class="p">,</span> <span class="s">'hs'</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">288</span><span class="p">,</span> <span class="mi">96</span><span class="p">,</span> <span class="bp">True</span><span class="p">,</span> <span class="s">'hs'</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
                <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">576</span><span class="p">,</span> <span class="mi">96</span><span class="p">,</span> <span class="bp">True</span><span class="p">,</span> <span class="s">'hs'</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">576</span><span class="p">,</span> <span class="mi">96</span><span class="p">,</span> <span class="bp">True</span><span class="p">,</span> <span class="s">'hs'</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="mi">576</span><span class="p">,</span> <span class="bp">True</span><span class="p">,</span> <span class="s">'hs'</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                <span class="mi">1024</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">cfgs</span>

</code></pre></div></div>

<h2 id="model-summary"><strong>Model Summary</strong></h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">configs</span> <span class="o">=</span> <span class="n">Config</span><span class="p">()</span>
<span class="n">cfgs_small</span> <span class="o">=</span> <span class="n">configs</span><span class="p">.</span><span class="n">small</span><span class="p">()</span>
<span class="n">cfgs_large</span> <span class="o">=</span> <span class="n">configs</span><span class="p">.</span><span class="n">large</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">large_model</span> <span class="o">=</span> <span class="n">MobileNetV3</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">cfgs_large</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">summary</span><span class="p">(</span><span class="n">large_model</span><span class="p">,</span> <span class="n">input_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="s">'cpu'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>====================================================================================================
Layer (type:depth-idx)                             Output Shape              Param #
====================================================================================================
MobileNetV3                                        [2, 1000]                 --
├─Sequential: 1-1                                  [2, 16, 112, 112]         --
│    └─Conv2d: 2-1                                 [2, 16, 112, 112]         432
│    └─BatchNorm2d: 2-2                            [2, 16, 112, 112]         32
│    └─Hardswish: 2-3                              [2, 16, 112, 112]         --
├─Sequential: 1-2                                  [2, 160, 7, 7]            --
│    └─InvResBlock: 2-4                            [2, 16, 112, 112]         --
│    │    └─Sequential: 3-1                        [2, 16, 112, 112]         464
│    └─InvResBlock: 2-5                            [2, 24, 56, 56]           --
│    │    └─Sequential: 3-2                        [2, 24, 56, 56]           3,440
│    └─InvResBlock: 2-6                            [2, 24, 56, 56]           --
│    │    └─Sequential: 3-3                        [2, 24, 56, 56]           4,440
│    └─InvResBlock: 2-7                            [2, 40, 28, 28]           --
│    │    └─Sequential: 3-4                        [2, 40, 28, 28]           9,458
│    └─InvResBlock: 2-8                            [2, 40, 28, 28]           --
│    │    └─Sequential: 3-5                        [2, 40, 28, 28]           20,510
│    └─InvResBlock: 2-9                            [2, 40, 28, 28]           --
│    │    └─Sequential: 3-6                        [2, 40, 28, 28]           20,510
│    └─InvResBlock: 2-10                           [2, 80, 14, 14]           --
│    │    └─Sequential: 3-7                        [2, 80, 14, 14]           32,080
│    └─InvResBlock: 2-11                           [2, 80, 14, 14]           --
│    │    └─Sequential: 3-8                        [2, 80, 14, 14]           34,760
│    └─InvResBlock: 2-12                           [2, 80, 14, 14]           --
│    │    └─Sequential: 3-9                        [2, 80, 14, 14]           31,992
│    └─InvResBlock: 2-13                           [2, 80, 14, 14]           --
│    │    └─Sequential: 3-10                       [2, 80, 14, 14]           31,992
│    └─InvResBlock: 2-14                           [2, 112, 14, 14]          --
│    │    └─Sequential: 3-11                       [2, 112, 14, 14]          214,424
│    └─InvResBlock: 2-15                           [2, 112, 14, 14]          --
│    │    └─Sequential: 3-12                       [2, 112, 14, 14]          386,120
│    └─InvResBlock: 2-16                           [2, 160, 7, 7]            --
│    │    └─Sequential: 3-13                       [2, 160, 7, 7]            429,224
│    └─InvResBlock: 2-17                           [2, 160, 7, 7]            --
│    │    └─Sequential: 3-14                       [2, 160, 7, 7]            797,360
│    └─InvResBlock: 2-18                           [2, 160, 7, 7]            --
│    │    └─Sequential: 3-15                       [2, 160, 7, 7]            797,360
├─Sequential: 1-3                                  [2, 960, 7, 7]            --
│    └─Conv2d: 2-19                                [2, 960, 7, 7]            153,600
│    └─BatchNorm2d: 2-20                           [2, 960, 7, 7]            1,920
│    └─Hardswish: 2-21                             [2, 960, 7, 7]            --
├─AdaptiveAvgPool2d: 1-4                           [2, 960, 1, 1]            --
├─Sequential: 1-5                                  [2, 1000]                 --
│    └─Linear: 2-22                                [2, 1280]                 1,230,080
│    └─Hardswish: 2-23                             [2, 1280]                 --
│    └─Dropout: 2-24                               [2, 1280]                 --
│    └─Linear: 2-25                                [2, 1000]                 1,281,000
====================================================================================================
Total params: 5,481,198
Trainable params: 5,481,198
Non-trainable params: 0
Total mult-adds (M): 433.24
====================================================================================================
Input size (MB): 1.20
Forward/backward pass size (MB): 140.91
Params size (MB): 21.92
Estimated Total Size (MB): 164.04
====================================================================================================
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">small_model</span> <span class="o">=</span> <span class="n">MobileNetV3</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">cfgs_small</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">summary</span><span class="p">(</span><span class="n">small_model</span><span class="p">,</span> <span class="n">input_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="s">'cpu'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>====================================================================================================
Layer (type:depth-idx)                             Output Shape              Param #
====================================================================================================
MobileNetV3                                        [2, 1000]                 --
├─Sequential: 1-1                                  [2, 16, 112, 112]         --
│    └─Conv2d: 2-1                                 [2, 16, 112, 112]         432
│    └─BatchNorm2d: 2-2                            [2, 16, 112, 112]         32
│    └─Hardswish: 2-3                              [2, 16, 112, 112]         --
├─Sequential: 1-2                                  [2, 96, 7, 7]             --
│    └─InvResBlock: 2-4                            [2, 16, 56, 56]           --
│    │    └─Sequential: 3-1                        [2, 16, 56, 56]           612
│    └─InvResBlock: 2-5                            [2, 24, 28, 28]           --
│    │    └─Sequential: 3-2                        [2, 24, 28, 28]           3,864
│    └─InvResBlock: 2-6                            [2, 24, 28, 28]           --
│    │    └─Sequential: 3-3                        [2, 24, 28, 28]           5,416
│    └─InvResBlock: 2-7                            [2, 40, 14, 14]           --
│    │    └─Sequential: 3-4                        [2, 40, 14, 14]           13,736
│    └─InvResBlock: 2-8                            [2, 40, 14, 14]           --
│    │    └─Sequential: 3-5                        [2, 40, 14, 14]           55,340
│    └─InvResBlock: 2-9                            [2, 40, 14, 14]           --
│    │    └─Sequential: 3-6                        [2, 40, 14, 14]           55,340
│    └─InvResBlock: 2-10                           [2, 48, 14, 14]           --
│    │    └─Sequential: 3-7                        [2, 48, 14, 14]           21,486
│    └─InvResBlock: 2-11                           [2, 48, 14, 14]           --
│    │    └─Sequential: 3-8                        [2, 48, 14, 14]           28,644
│    └─InvResBlock: 2-12                           [2, 96, 7, 7]             --
│    │    └─Sequential: 3-9                        [2, 96, 7, 7]             91,848
│    └─InvResBlock: 2-13                           [2, 96, 7, 7]             --
│    │    └─Sequential: 3-10                       [2, 96, 7, 7]             294,096
│    └─InvResBlock: 2-14                           [2, 96, 7, 7]             --
│    │    └─Sequential: 3-11                       [2, 96, 7, 7]             294,096
├─Sequential: 1-3                                  [2, 576, 7, 7]            --
│    └─Conv2d: 2-15                                [2, 576, 7, 7]            55,296
│    └─BatchNorm2d: 2-16                           [2, 576, 7, 7]            1,152
│    └─Hardswish: 2-17                             [2, 576, 7, 7]            --
├─Squeeze_Excite: 1-4                              [2, 576, 7, 7]            --
│    └─AdaptiveAvgPool2d: 2-18                     [2, 576, 1, 1]            --
│    └─Sequential: 2-19                            [2, 576]                  --
│    │    └─Linear: 3-12                           [2, 144]                  83,088
│    │    └─ReLU: 3-13                             [2, 144]                  --
│    │    └─Linear: 3-14                           [2, 576]                  83,520
│    │    └─Hardsigmoid: 3-15                      [2, 576]                  --
├─AdaptiveAvgPool2d: 1-5                           [2, 576, 1, 1]            --
├─Sequential: 1-6                                  [2, 1000]                 --
│    └─Linear: 2-20                                [2, 1024]                 590,848
│    └─Hardswish: 2-21                             [2, 1024]                 --
│    └─Dropout: 2-22                               [2, 1024]                 --
│    └─Linear: 2-23                                [2, 1000]                 1,025,000
====================================================================================================
Total params: 2,703,846
Trainable params: 2,703,846
Non-trainable params: 0
Total mult-adds (M): 113.38
====================================================================================================
Input size (MB): 1.20
Forward/backward pass size (MB): 45.30
Params size (MB): 10.82
Estimated Total Size (MB): 57.32
====================================================================================================
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">224</span><span class="p">,</span><span class="mi">224</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">large_model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">out</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>torch.Size([2, 1000])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>
:ET