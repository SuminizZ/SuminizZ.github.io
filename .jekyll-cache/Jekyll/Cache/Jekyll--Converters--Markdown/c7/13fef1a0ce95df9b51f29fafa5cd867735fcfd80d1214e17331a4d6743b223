I"Œ <p><br /></p>

<h2 id="unsupervised-learning"><strong>Unsupervised Learning</strong></h2>
<p><br /></p>

<ul>
  <li>training set w/o any label on it</li>
  <li>you are given <strong>an unlabeled dataset</strong> and just ask algorithm to <strong>find the structure of data</strong>
    <ul>
      <li>and make it clustered : Clustering Algorithm</li>
    </ul>
  </li>
  <li>Applications
    <ul>
      <li>Market segmentation - group customers into different market segments</li>
      <li>Social network analysis - Facebook ‚Äúsmartlists‚Äù</li>
      <li>Organizing computer clusters and data centers for network layout and location</li>
      <li>Astronomical data analysis - Understanding galaxy formation</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="k-means-algorithm"><strong>K-Means Algorithm</strong></h2>
<p><br /></p>

<ul>
  <li>Repeat)
    <ul>
      <li>Step1. Randomly allocate several points as the cluster centroids
        <ul>
          <li>you can have as many cluster centroids as clusters you want to do (K cluster centroids, in fact)</li>
        </ul>
      </li>
      <li>Step2. Cluster assignment step
        <ul>
          <li>for every each data point, assign them to clusters depending on the proximity with each cluster centroids</li>
          <li>and color them with the color of the centroids that they are close to</li>
        </ul>
      </li>
    </ul>

    <p><img src="https://user-images.githubusercontent.com/92680829/157780154-11cb254b-ad0b-4f58-b546-90da8117aab5.png" width="700" />
<br /></p>
  </li>
  <li>Step3. Move centroid step
    <ul>
      <li>move them to the average location of all points colored with the same colour</li>
    </ul>

    <p><img src="https://user-images.githubusercontent.com/92680829/157780644-9a174167-4ee5-4173-8c94-ab68b3a8ad65.png" width="600" />
<br /></p>
  </li>
  <li>if you keep running additional iterations,
    <ul>
      <li>when the location of the centroids equals to th avg of clustered data</li>
      <li><strong>Convergence</strong> : end iteration</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h3 id="summary-of-k-means-algorithm"><strong>Summary of K-means Algorithm</strong></h3>
<p><br /></p>

<ul>
  <li>Input:
    <ul>
      <li>K (number of clusters in the data)
        <ul>
          <li>how to choose K will be covered later</li>
        </ul>
      </li>
      <li>Training set {x1, x2, x3 ‚Ä¶, xn)</li>
    </ul>
  </li>
  <li>Algorithm:
    <ol>
      <li>Randomly initialize K cluster centroids as {Œº1, Œº2, Œº3 ‚Ä¶ ŒºK}</li>
      <li>for i from 1 to m (m = size of dataset)
        <ul>
          <li>c(i) : from 1 to K, <strong>index</strong> of the centroid that is closet to x(i)</li>
        </ul>
      </li>
      <li>for k from 1 to K (K = size of centroids)
        <ul>
          <li>Œº(k) : average of data points assigned to kth centorid cluster = location of the centorids (moving centroids step)</li>
          <li>Œºc(i) : centroid cluster with the index of c(i), the cluster to which x(i) has been assigned</li>
        </ul>
      </li>
      <li>Repeat the loop
        <ul>
          <li>Loop1 :
            <ul>
              <li>repeatedly sets the c(i) variable to be the index of the variable of cluster centroid closest to xi</li>
              <li>i.e. take ith example, measure squared distance to each cluster centroid, assign c(i) to the cluster closest
                <ul>
                  <li>min [ x(i) - Œº(k) ]^2</li>
                </ul>
              </li>
            </ul>
          </li>
          <li>Loop2 :
            <ul>
              <li>depending on the results of the first loop, move all centroids to the average of newly assigned data points</li>
              <li>= reset the Œº(k) for k in 1 to K</li>
            </ul>
          </li>
        </ul>
      </li>
    </ol>
  </li>
  <li>What if there‚Äôs a centroid with no data
    <ul>
      <li>Remove that centroid, so end up with K-1 classes</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h3 id="k-means-for-non-separated-clusters"><strong>K-means for non-separated clusters</strong></h3>
<p><br /></p>

<ul>
  <li>often K-means is applied to datasets where there aren‚Äôt well defined clusters
    <ul>
      <li>e.g. T-shirt sizing :
        <ul>
          <li>k-means can even cluster the data that doesn‚Äôt look to have any clear clusters</li>
          <li>example of market segmentation where you use k-means to separate your market and design the products depending on it</li>
          <li><img src="https://user-images.githubusercontent.com/92680829/157783656-5507974b-7a8a-4334-a6e5-64ece66950be.png" width="300" /></li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<hr />

<h2 id="optimization-objectives-of-k-means"><strong>Optimization Objectives of K-means</strong></h2>
<ul>
  <li>cost function that k-means algorithm tries to minimize</li>
  <li>that is the sum of sqaured distance between x(i) and Œºc(i)
    <ul>
      <li><img src="https://user-images.githubusercontent.com/92680829/157784513-81e710a2-2771-4a51-8dbe-286c8b9e1278.png" width="500" /></li>
    </ul>
  </li>
</ul>

<p><br /></p>

<ul>
  <li>optmization objective : min J(c,Œº)
    <ul>
      <li>The <strong>cluster assignment step</strong> is minimizing J(‚Ä¶) with respect to c1, c2 ‚Ä¶ ci
        <ul>
          <li>i.e. find the centroid (c(i)) closest to each example (x(i))</li>
          <li>Doesn‚Äôt change the centroids themselves</li>
        </ul>
      </li>
      <li>The move centroid step
        <ul>
          <li>choosing the values of Œº which minimizes J(‚Ä¶) with respect to Œºc(i)..</li>
          <li>this step actually changes the cluster centroids</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>So, we‚Äôre partitioning the algorithm into two parts
    <ul>
      <li>First part minimizes the c variables</li>
      <li>Second part minimizes the J variables</li>
    </ul>
  </li>
  <li>We can use this knowledge to help <strong>debug our K-means algorithm</strong></li>
</ul>

<hr />

<h2 id="random-initialization--debugging"><strong>Random Initialization : Debugging</strong></h2>
<ul>
  <li>how k-means can avoid converging to <strong>Local Optima</strong>
    <ul>
      <li>Randomize initial K
        <ul>
          <li>should have K &lt; m (m = size of x)</li>
          <li>randomly pick K from training examples (i(1)‚Ä¶ i(m))</li>
          <li>set Œº1 ‚Ä¶ Œºk equal to these K examples</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>K means can converge to different solutions depending on the initialization setup
    <ul>
      <li>Risk of local optimum</li>
      <li><img src="https://user-images.githubusercontent.com/92680829/157786991-b70a266d-da4e-4935-96aa-09b715ef9b83.png" width="500" /></li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h3 id="try-multiple-random-initialization"><strong>Try Multiple Random Initialization</strong></h3>
<ul>
  <li>
    <p><img src="https://user-images.githubusercontent.com/92680829/157787440-ffa3c99a-b6ba-4561-b1e9-b062c27e6351.png" width="300" /></p>
  </li>
  <li>Now you have 100 differenct cases of clustering and cost</li>
  <li>pick one with lowest cost</li>
</ul>

<h3 id="choosing-the-number-of-clusters--k"><strong>Choosing the number of clusters : K</strong></h3>
<ul>
  <li>most common way : choosing it manually by observing visualization result</li>
  <li>since its not labeled dataset, it‚Äôs generally quite ambiguous to tell how many clusters are there</li>
  <li>
    <p>a few of them are presented below</p>
  </li>
  <li><strong>1. Elbow Method</strong>
    <ul>
      <li>plot J by every K size that you‚Äôve tried</li>
      <li><img src="https://user-images.githubusercontent.com/92680829/157788594-25d597eb-18b7-468b-be31-bd58b845944d.png" width="300" /></li>
      <li>ideally, you can set your k where the ‚Äúelbow‚Äù is formed</li>
      <li>but practically, usually the location of elbow is not so clear and still seems ambiguous which K is the best clustering size</li>
    </ul>
  </li>
  <li>
    <ol>
      <li><strong>Considering your Business Considerations</strong>
        <ul>
          <li>people usually use k-means for later/downstream purpose in market segmentation</li>
          <li>not just in terms of minimizing cost, you can consider other issues related to your business or market</li>
        </ul>
      </li>
    </ol>
  </li>
</ul>

:ET