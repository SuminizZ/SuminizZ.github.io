---
layout: post
title : "[Paper Review] Path Aggregation Network for Instance Segmentation (PANet, 2018)"
img: papers/objd/panet.png
categories: [papers-objd]  
tag : [Paper Review, Object Detection, PANet, YOLO V4]
toc : true
toc_sticky : true
---

## **Outlines**
- [**Reference**](#reference)
- [**Implementation with PyTorch**](#implementation-with-pytorch)
- [**YOLO : Single-State Object Detection**](#yolo--single-state-object-detection)
- [**YOLO Backbone Architecture : Feature Extractor and Region Proposals**](#yolo-backbone-architecture--feature-extractor-and-region-proposals)
- [**Customize PASCAL VOC Dataset**](#customize-pascal-voc-dataset)
- [**Process the Predicted Bounding Boxes from YOLO Model and Obtain Final Target Boxes**](#process-the-predicted-bounding-boxes-from-yolo-model-and-obtain-final-target-boxes)
    - [**Step 1 : Convert bounding boxes relative to cell ratio into entire image ratio**](#step-1--convert-bounding-boxes-relative-to-cell-ratio-into-entire-image-ratio)
    - [**Step 2 : Non-Maximal Suppression onto Predicted Bounding Boxes**](#step-2--non-maximal-suppression-onto-predicted-bounding-boxes)
- [**Calculate Mean Average Precison (mAP) between Predicted Boxes and Ground Truths**](#calculate-mean-average-precison-map-between-predicted-boxes-and-ground-truths)
- [**Computing Loss and Optimizing the Model**](#computing-loss-and-optimizing-the-model)
- [**Training Result & Display Predicted Anchors from Trained Model onto Image**](#training-result--display-predicted-anchors-from-trained-model-onto-image)

<br/>

## **Reference**

<br/>

- [**Path Aggregation Network for Instance Segmentation, Shu Liu, 2018**](https://arxiv.org/pdf/1803.01534v4.pdf){:target="_blank"}

<br/>

## **Architecture of Path Aggregation Network (PANet)**

<br/>

&emsp;&emsp; **Figure 1. Illustration of our framework.**

<img width="900" alt="image" src="https://github.com/SuminizZ/Algorithm/assets/92680829/59ec2dbc-8b36-405f-bcba-a9960e7a5135">

<br/>

- Path Aggregation Network (PANet) is an improvement from Feature Pyramidal Network (FPN) that is used in Mask R-CNN for instance segmentation.

- With a novel structures added to the backbone of FPN (Figure 1.(a)), PANet boosts the information flow in instance segmentation. 

<br/>

### **Figure 1.(b) Bottom-Up Path Augmentation**

<br/>

&emsp;&emsp; **Figure 2. Building block of Bottom-Up Augmentation Path**

&emsp;&emsp; <img width="350" alt="image" src="https://github.com/SuminizZ/Algorithm/assets/92680829/674ed298-3244-41ae-aa9f-5e76aae8d603">

<br/>

- While FPN introduced the concept of a top-down pathway that combines high-level semantic information with low-level spatial details, PANet further improves this by incorporating a bottom-up pathway that augments the information flow from low-level to higher levels. 

- While lacking semantic capacity, low-level patterns possess relatively accurate instance localization with high responses to edges, which is crucial in instance segmentation. 

- Hence, propagating low-level features to higher level maps significantly enhances the localization capability of the entire feature hierarchy. 

- Despite the presence of a path connecting low-level structures to the topmost features in FPN, the length of this path are excessively long, extending to over 100 layers (<span style='color:red'>red dahsed line</span> in **Figure 1.**). 

- Bottom-up path introduced in PANet can effectively shorten this path to less than 10 layers (<span style='color:green'>green dahsed line</span> in **Figure 1.**) with extra lateral connections projecting from a feature map at each level in top-down pathway.

- Creating a shortcut connecting low-level to higher levels of the pyramid, PANet can transmit much stronger and well-preserved localization information stored in lower-level features across the entire pyramid compared to FPN.

<br/>

### **Figure 1.(c) Adaptive Feature Pooling**

<br/>

&emsp;&emsp; **Figure 6. Illustration of Adaptive Feature Pooling**

<img width="650" alt="image" src="https://github.com/SuminizZ/Algorithm/assets/92680829/8b137548-b16b-4d9e-8deb-c8800a23bf70">

<br/>

- In FPN, proposals are assigned to a feature level according to the size of proposals. Small proposals are assigned to low-level features with high resolution and large proposals are to higher level features with lower resolution. 

- This kind of strategy is based on an insight that smaller objects are more sensitive to spatial resolution to maintain fine grained details, whereas larger objects are largely robust to smaller details and rather depend on richer semantic context captured from large receptive field.

- Although simple and effective, this separation of level based on the proposal scale can lead to non-optimal results where proposals with non-significant pixel difference (like, 10 pixel) are assigned to different level and utilized to make separate predictions. 

- Further, authors of the paper suggested that importance of features may not be strictly related to the size of objects.

- Based on these ides, they added an adaptive feature pooling layer to fuse all these feature maps pooled from different levels into a single integrated map.

- Allowing access for small proposals to richer context information captured in higher levels and large proposals to low level features that contain fine details and precise localization benefits the networks to extract features that are more beneficial for following prediction tasks.

<br/>

&emsp;&emsp; **Figure 3. Ratio of Features Pooled from Different feature levels**

<img width="600" alt="image" src="https://github.com/SuminizZ/Algorithm/assets/92680829/01439ad8-a4c4-42b5-892f-7226a2b25f28">

<br/>

- Each colored line represents the proposals with certain size (that are originally assigned to designated level in FPN) and horizontal axis denotes the source of pooled features.

- Shows how features extracted from different levels are distributed in proposals with different sizes. 

- While there may be some variations in the ratio, feature from all levels coexist in each proposal, indicating that mulitple levels of features contribute to the proposal of a single scale.

<br/>

### **Figure 1.(e) Fully-Connected Fusion**

<br/>

- Mask R-CNN adopted a tiny Fully-Convolutional Network (FCN) to predict masks instead of fully-connected layers (fc layers) based on an idea that mask prediction requires dense pixel-wise segmentation that preserves spatial representation of feature maps rather than flattening them into a vector. 

- However, PANet combines two of these structures, utilizing both FCN and fc layers for instance segmentation, to exploit the distinct advantages that each network can provide."

- While FCN can give pixel-based prediction with shared parameters 
