---
layout: post
title : "[Paper Review] Streaming Graph Neural Networks (DGNN, 2018)"
img: papers/gnn/dgnn.png
categories: [papers-gnn]  
tag : [Paper Review, Graph, GNN]
toc : true2020
toc_sticky : true
---

## **Outlines**
- [**Reference**](#reference)
- [**Deep Learning for Graph Data**](#deep-learning-utilized-to-analyze-graph-data)
- [**0. Notations and Preliminaries**](#0-notations-and-preliminaries)
- [**1. Graph Recurrent Neural Networks (RNNs)**](#1-graph-recurrent-neural-networks-rnns)
- [**Graph Convolutional Networks (CNNs)**](#graph-convolutional-networks-cnns)
- [**Graph AutoEncoders (GAE)**](#graph-autoencoders-gaes)
- [**Graph Reinforcement Learning (RL)**](#graph-reinforcement-learning-rl)
- [**Graph Adversarial Methods**](#graph-adversarial-methods)

<br/>


## **Reference**

<br/>

- [**Streaming Graph Neural Networks, Ma et al, 2018**](https://arxiv.org/pdf/1810.10627.pdf){:target="_blank"}

<br/>

## **1. Dynamic Graph Neural Networks (DGNN)**

<br/>

- As graphs in real-world applications are inherently dynamic, this paper aims to design a graph neural networks that models dynamic graphs along with temporal information.   

- DGNN utilizes a modified LSTM to update the graph when new interactions occur between nodes.

- Further, it propagates the influence of the new interaction to the neighboring nodes. 

- These update and propagation steps incorporate consideration of the time interval between interactions.


<br/>

## **2. Frameworks of DGNN**

<br/>

&emsp; **Figure 1. An overview of DGNN when a new interaction happened at time t7 from v2 to v5.**

&emsp; <img src="https://github.com/SuminizZ/Algorithm/assets/92680829/3c7058f2-bf94-49df-be27-f3af2dacc735" width="800">


- **Interactiong nodes** : two nodes that are directly involved in the interaction, here $\large v_{2}$ and $\large v_{5}$.

- **Influenced nodes** : 

    - nodes that are influenced by the interaction, limited to the nodes close to interacting nodes.
    
    - $\large v_{1}, v_{3}, v_{6}, v_{7}$

- $\large v_{s}$ and $\large v_{g}$ : source node and target node. 

- Interation from $\large v_{s}$ to $\large v_{g}$ at time $t$ : $\large (v_{s}, v_{g}, t)$
    
    - at time t7 from v2 to v5 : $\large (v_{2}, v_{5}, t_{7})$ 

<br/>

### **2.1. Update Component**

<br/>

&emsp; **Figure 2. An overview of the operations of update component with the focus on node $\large v_{2}$ and its connections**

&emsp; <img src="https://github.com/SuminizZ/Algorithm/assets/92680829/4a18856b-f204-4dba-91e2-576f27b35d20" width="600">

- Overview of the operations of the update component with the focus on $\large v_{2}$ in the dynamic graph illustrated in Figure 1. 

- There are three interactions involving node $\large v_{2}$, {$\large v_{2},v_{1},t_{0}$}, {$\large v_{7}, v_{2}, t_{3}$}and {$\large v_{2}, v_{5}, t_{7}$}.

- Sequence of interactions are recurrently applied to update the information of affected nodes.

    - Next component of the sequence takes the output of the previous component as an input. 

    - Only stores the latest information about each node. 

- As shown in the figure 2., single update component consists of three units, **interact unit**, **S or G-Ipdate unit**, and **Merge unit**. 

    &emsp; **Figure 3. Overview of the operations performed within each unit in the update component when an interaction {$\large v_{2}, v_{5}, t_{7}$} happened.**

    &emsp; <img src="https://github.com/SuminizZ/Algorithm/assets/92680829/b67f142c-fe72-43bc-bff7-70176c450f7e" width="750">

<br/>

- Before getting into the details of each unit, let's specify the **information stored per each node**. 

    &emsp; **Figure 3.(a)**

    &emsp; <img src="https://github.com/SuminizZ/Algorithm/assets/92680829/8b945fa5-7685-4542-8d97-8c8f57569fd8" width="220">

    - As a node can act as both source and target, there are two sets of cell memories and hidden states, one for the role as a source and the other for target. 

    - $\large C_{v}^{s}(t-),\,\, h_{v}^{s}(t-),\,\, C_{v}^{g}(t-),\,\, h_{v}^{g}(t-)$ : cell memories and hidden states of source and target nodes at time $t-$.

    - $\large t_{7}-$ denotes the most recent time before the interaction at time $\large t_{7}$. 

        - In case of $\large v_{2}$,  $\large t_{7}-$ is $\large t_{3}$ and for $\large v_{5}$, $\large t_{6}$.
    
    - $\large u_{v_{x}}$ contains the general features computed from interact unit, which holds the interaction information between source and taraget nodes.

- Carrying these information updated from previous interaction, interacting nodes enter into following subsequent units. 

<br/>

#### **2.1.1. Interact Unit**

<br/>

&emsp; **Figure 3.(b)**

&emsp; <img src="https://github.com/SuminizZ/Algorithm/assets/92680829/dadefe40-6feb-4b56-9dfb-944b8e54e408" width="200">

- This unit is a learned feed forward network for computing the interaction information betwen source and target nodes.

- **Formulation** : 

    &emsp;<img src="https://github.com/SuminizZ/Algorithm/assets/92680829/6e53a0bf-f62a-47c9-a388-2002c65df01c" width="370">

- Each of $\large u_{v_{2}}(t_{7}-)$ (source) and $\large u_{v_{5}}(t_{7}-)$ (target) enters into the model to generate interaction information $\large e(t)$. 

- $\large W_{1}, W_{2}, b_{e}$ are the learned paramters and $\large act$ is the activation function (e.g, sigmoid or tanh).

- Also compute $\Delta_{t_{s}}$ and $\Delta_{t_{g}}$, time intervals between the latest previous interaction time and the current interaction.

<br/>

#### **2.1.2. Update Unit**

<br/>

&emsp; **Figure 3.(b)**

&emsp; <img src="https://github.com/SuminizZ/Algorithm/assets/92680829/0612b2fb-96ad-43c6-9d2d-f384a0cfcc63" width="400">

- Modified LSTM is used in this unit. 

- There are two types of update units, S-Update and G-Update, to which corresponding information of the nodes (source or target) are passed.

    - Input of the unit consists of four components, $\large C_{v_{x}}^{x}(t_{7}-),\,\, h_{v}^{x}(t_{7}-),\,\, e(t_{7}),\,\, \Delta_{t_{x}}$. Here x is s and g for source and target, respectively. 

    - S and G update units share same structure with separately learned weigths. 

- In each unit, new $\large C_{v}(t_{7}),\,\, h_{v}(t_{7})$ are computed through the modified LSTM with corresponding formulations.

    &emsp; **Figure 4. Illustration of the update unit**

    <!-- &emsp; <img src="https://github.com/SuminizZ/Algorithm/assets/92680829/77e18bf0-931b-429c-bd47-a6c30ad9a1e7" width="900"> -->

    - part (2), (4) are short memory and long term memory, respectively.

    - While long term momory remains unchanged, short term memory is discounted by the discount function $\large g$ that considers the time interval between interactions.

        - As $\large g$ is a decreasing function, larger $\Delta_{t}$ results in smaller $g(\Delta_{t})$, which is to be multiplied to short term memory.

        - Intuitively, this operation reflects the nutural tendency for older memories to be forgotten more, while relatively recent memory are retained to a greater extent.

    - Part (5) in the formulations is the final adjusted cell memory $\large C_{v}^{\*}(t-)$, which propagates out of the blue dashed box to the standard LSTM unit.

    - The formulations for the rest part of the update unit are as follows

        <img src="https://github.com/SuminizZ/Algorithm/assets/92680829/c4840831-6d97-413f-9a8d-6d7061d6f6b3" width="450">

    - To summarize all the procedures present in update unit (from eq.(2) to eq.(11))

        <img src="https://github.com/SuminizZ/Algorithm/assets/92680829/a43c1c6a-d808-450a-b660-e8884742a0f8" width="450">

<br/>

#### **2.1.3. Merge Unit**

<br/>

- Depending on whether the node entered into update unit is a source node or target node, it only passes through one of the two units (S-Update or G-Update).

- As each unit only updates the corresponding information of the node (source or target), other type of information (for S-update, target information) remains unchanged as the previous state. 

- Hence, node $\large v_{s}$ has $\large h_{v_{s}}^{s}(t)$ and $\large h_{v_{g}}^{g}(t-)$ as the output of S-Update and node $\large v_{g}$ has $\large h_{v_{s}}^{s}(t-)$ and $\large h_{v_{g}}^{g}(t)$ as the output of G-Update unit.

- Combining these two hidden state features of source and target, merge unit generates general features $\large u_{v_{s}}(t)$ or $\large u_{v_{g}}(t)$ as follows

    <img src="https://github.com/SuminizZ/Algorithm/assets/92680829/7a78ca5a-5a43-472f-9d0a-07c33cbfcccd" width="450">


- Finally, the output of the update component is the udpated information of the interacting nodes after the interaction {$\large v_{2},v_{5},t_{7}$}

    - For the source node, updated information includes $\large C_{v_{s}}^{s}(t),\,\, h_{v_{s}}^{s}(t),\,\, C_{v_{g}}^{g}(t-),\,\, h_{v_{g}}^{g}(t-), \,\,u_{v_{s}}(t)$

    - For the target node, $\large C_{v_{g}}^{g}(t), \,\,h_{v_{g}}^{g}(t),\,\, C_{v_{s}}^{s}(t-),\,\, h_{v_{s}}^{s}(t-), \,\,u_{v_{g}}(t)$

<br/>

### **2.2. Propagation Component**

<br/>

- After updating the information of interacting nodes, DGNN also consider the sequential influence of the interaction to adjacent nodes, referred to as influenced nodes. 

- Authors limit the influenced nodes as current neighbors of the two interacting nodes with following three reasons.

    - 
